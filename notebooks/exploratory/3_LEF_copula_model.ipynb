{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copulas.multivariate import GaussianMultivariate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from scipy.stats import anderson\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load historical data (replace this with your actual historical data)\n",
    "historical_data = pd.read_csv('historical_data.csv')\n",
    "\n",
    "# Shift the water level so the model is training on using the previous month's water level\n",
    "historical_data['Previous_Month_Water_Level'] = historical_data['Water_Level'].shift(1)\n",
    "# Drop the first line of data since previous_month_water_level is now nan\n",
    "historical_data = historical_data.dropna()\n",
    "\n",
    "# Extract features (precipitation, evaporation, runoff, water levels, and month) and target (net basin supply) from historical data\n",
    "features = historical_data[['Precipitation', 'Evaporation', 'Runoff', 'Previous_Month_Water_Levels', 'Date']]\n",
    "features['Month'] = pd.to_datetime(features['Date']).dt.month  # Extract month from date\n",
    "features = features.drop(columns=['Date'])\n",
    "\n",
    "target = historical_data['Net_Basin_Supply']\n",
    "\n",
    "# Normalize features and target\n",
    "scaler_features = MinMaxScaler()\n",
    "scaler_target = MinMaxScaler()\n",
    "\n",
    "features[['Precipitation', 'Evaporation', 'Runoff', 'Previous_Month_Water_Levels']] = scaler_features.fit_transform(features[['precipitation', 'evaporation', 'runoff', 'water_levels']])\n",
    "target_normalized = scaler_target.fit_transform(target.values.reshape(-1, 1)).flatten()\n",
    "\n",
    "# One-hot encode month feature\n",
    "month_encoder = OneHotEncoder()\n",
    "month_encoded = month_encoder.fit_transform(features[['Month']])\n",
    "features.drop(columns=['Month'], inplace=True)\n",
    "\n",
    "# Concatenate encoded month feature with other features\n",
    "features_normalized = np.concatenate([features.values, month_encoded.toarray()], axis=1)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_normalized, target_normalized, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit copula model on training data\n",
    "copula = GaussianMultivariate()\n",
    "copula.fit(X_train, y_train)\n",
    "# Save the trained copula model for net basin supply prediction\n",
    "joblib.dump(copula, 'copula_model_net_basin_supply.pkl')\n",
    "\n",
    "# Validate copula model on testing data\n",
    "\n",
    "# Visual inspection: Plot empirical copula against fitted copula\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test, copula.partial_fit(X_test), label='Empirical vs Fitted')\n",
    "plt.xlabel('Actual Net Basin Supply')\n",
    "plt.ylabel('Predicted Net Basin Supply')\n",
    "plt.title('Actual vs Predicted Net Basin Supply')\n",
    "plt.legend()\n",
    "\n",
    "# Goodness-of-fit test: Anderson-Darling test\n",
    "test_statistic, critical_values, significance_level = anderson(y_test)\n",
    "print('Anderson-Darling test statistic:', test_statistic)\n",
    "print('Critical values:', critical_values)\n",
    "print('Significance level:', significance_level)\n",
    "\n",
    "# Out-of-sample testing: Compare predictions with actual values\n",
    "predicted_values = scaler_target.inverse_transform(copula.partial_fit(X_test).reshape(-1, 1)).flatten()\n",
    "mse = np.mean((scaler_target.inverse_transform(y_test.reshape(-1, 1)).flatten() - predicted_values) ** 2)\n",
    "print('Mean Squared Error (MSE):', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained copula model for net basin supply prediction\n",
    "copula_model = joblib.load('copula_model_net_basin_supply.pkl')\n",
    "\n",
    "# Prepare forecasted data\n",
    "forecasted_runoff = pd.read_csv('forecasted_runoff.csv')  # Assuming your forecasted runoff data is stored in a CSV file\n",
    "forecasted_precipitation = pd.read_csv('forecasted_precipitation.csv')  # Assuming your forecasted precipitation data is stored in a CSV file\n",
    "forecasted_evaporation = pd.read_csv('forecasted_evaporation.csv')  # Assuming your forecasted evaporation data is stored in a CSV file\n",
    "last_month_water_level = pd.read_csv('last_month_water_level.csv')['water_level'].values[0]  # Assuming your last month water level data is stored in a CSV file\n",
    "\n",
    "# Concatenate the forecasted data into a single DataFrame\n",
    "forecasted_data = pd.concat([forecasted_runoff, forecasted_precipitation, forecasted_evaporation, last_month_water_level], axis=1)\n",
    "\n",
    "# Extract features from the forecasted data\n",
    "features = forecasted_data[['precipitation', 'evaporation', 'runoff', 'water_levels', 'month']]\n",
    "\n",
    "# One-hot encode month feature\n",
    "month_encoder = OneHotEncoder()\n",
    "month_encoded = month_encoder.fit_transform(features[['month']])\n",
    "features.drop(columns=['month'], inplace=True)\n",
    "\n",
    "# Concatenate encoded month feature with other features\n",
    "features = np.concatenate([features.values, month_encoded.toarray()], axis=1)\n",
    "\n",
    "# Normalize features\n",
    "scaler_features = MinMaxScaler()\n",
    "features_normalized = scaler_features.fit_transform(features)\n",
    "\n",
    "# Predict net basin supply for the next month\n",
    "predicted_net_basin_supply_normalized = copula_model.predict(features_normalized)\n",
    "\n",
    "# Inverse transform the predicted net basin supply to obtain the original scale\n",
    "scaler_target = copula_model.named_steps['copula'].marginal_distributions_['net_basin_supply']\n",
    "predicted_net_basin_supply = scaler_target.inverse_transform(predicted_net_basin_supply_normalized.reshape(-1, 1))\n",
    "\n",
    "# Create a DataFrame to store the predicted net basin supply\n",
    "predicted_net_basin_supply_df = pd.DataFrame(predicted_net_basin_supply, columns=['predicted_net_basin_supply'])\n",
    "\n",
    "print(\"Predicted net basin supply for the next month:\")\n",
    "print(predicted_net_basin_supply_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
