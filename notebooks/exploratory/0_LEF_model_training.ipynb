{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\fitzpatrick\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (24.1)\n",
      "Collecting pip\n",
      "  Downloading pip-24.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-24.2-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/1.8 MB 3.3 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.2/1.8 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.5/1.8 MB 3.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.0/1.8 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.8/1.8 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 6.8 MB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.1\n",
      "    Uninstalling pip-24.1:\n",
      "      Successfully uninstalled pip-24.1\n",
      "Successfully installed pip-24.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts pip.exe, pip3.12.exe and pip3.exe are installed in 'C:\\Users\\fitzpatrick\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!py -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel, ConstantKernel, RBF\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 126] The specified module could not be found. Error loading \"c:\\Users\\fitzpatrick\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstep2_preprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XArrayScaler, SeasonalFeatures, XArrayUnion\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstep3_modeling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DefaultEnsemble, BaggedXArrayRegressor\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstep3_modeling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgaussian_process\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SklearnGPModel, LaggedSklearnGP\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstep3_modeling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvar_models\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VAR, NARX\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstep3_modeling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BayesNN\n",
      "File \u001b[1;32mc:\\Users\\fitzpatrick\\NBS-Predictor-MVP-1\\notebooks\\exploratory\\src\\step3_modeling\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import the main functions from modeling.py\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgaussian_process\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\fitzpatrick\\NBS-Predictor-MVP-1\\notebooks\\exploratory\\src\\step3_modeling\\gaussian_process.py:10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstep3_modeling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelBase\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstep4_postprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m output_forecast_results\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lag_array, flatten_array\n\u001b[0;32m     12\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSklearnGPModel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLaggedSklearnGP\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSklearnGPModel\u001b[39;00m(ModelBase, ABC):\n",
      "File \u001b[1;32mc:\\Users\\fitzpatrick\\NBS-Predictor-MVP-1\\notebooks\\exploratory\\src\\utils.py:8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxr\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdateutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrelativedelta\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m relativedelta\n",
      "File \u001b[1;32mc:\\Users\\fitzpatrick\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\__init__.py:148\u001b[0m\n\u001b[0;32m    146\u001b[0m                 err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(ctypes\u001b[38;5;241m.\u001b[39mget_last_error())\n\u001b[0;32m    147\u001b[0m                 err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 148\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    150\u001b[0m     kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_preload_cuda_deps\u001b[39m(lib_folder, lib_name):\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 126] The specified module could not be found. Error loading \"c:\\Users\\fitzpatrick\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process import kernels\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from src.step1_data_loading.data_loading import load_data\n",
    "from src.step2_preprocessing.preprocessing import XArrayScaler, SeasonalFeatures, XArrayUnion\n",
    "from src.step3_modeling.ensemble import DefaultEnsemble, BaggedXArrayRegressor\n",
    "from src.step3_modeling.gaussian_process import SklearnGPModel, LaggedSklearnGP\n",
    "from src.step3_modeling.var_models import VAR, NARX\n",
    "from src.step3_modeling.nn import BayesNN\n",
    "from src.step3_modeling.metrics import summarize\n",
    "from src.step3_modeling.modeling import ModelBase\n",
    "from src.utils import create_rnbs_snapshot, flatten_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"'variable' is not a valid dimension or coordinate for Dataset with dimensions FrozenMappingWarningOnValuesAccess({'Date': 0, 'lake': 4, 'type': 4})\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#lake_data = load_data([\"rnbs\",\"temp\"]).dropna(\"Date\").transpose(\"Date\", \"lake\", ...)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m lake_data \u001b[38;5;241m=\u001b[39m load_data([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrnbs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecip\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevap\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemp\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mdropna(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mlake_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprecip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevap\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m), lake_data\u001b[38;5;241m.\u001b[39msel(\n\u001b[0;32m      5\u001b[0m     variable\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrnbs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\fitzpatrick\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xarray\\core\\dataset.py:3126\u001b[0m, in \u001b[0;36mDataset.sel\u001b[1;34m(self, indexers, method, tolerance, drop, **indexers_kwargs)\u001b[0m\n\u001b[0;32m   3058\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a new dataset with each array indexed by tick labels\u001b[39;00m\n\u001b[0;32m   3059\u001b[0m \u001b[38;5;124;03malong the specified dimension(s).\u001b[39;00m\n\u001b[0;32m   3060\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3123\u001b[0m \n\u001b[0;32m   3124\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3125\u001b[0m indexers \u001b[38;5;241m=\u001b[39m either_dict_or_kwargs(indexers, indexers_kwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 3126\u001b[0m query_results \u001b[38;5;241m=\u001b[39m \u001b[43mmap_index_queries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3127\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\n\u001b[0;32m   3128\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m drop:\n\u001b[0;32m   3131\u001b[0m     no_scalar_variables \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\fitzpatrick\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xarray\\core\\indexing.py:184\u001b[0m, in \u001b[0;36mmap_index_queries\u001b[1;34m(obj, indexers, method, tolerance, **indexers_kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m     options \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: method, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtolerance\u001b[39m\u001b[38;5;124m\"\u001b[39m: tolerance}\n\u001b[0;32m    183\u001b[0m indexers \u001b[38;5;241m=\u001b[39m either_dict_or_kwargs(indexers, indexers_kwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap_index_queries\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 184\u001b[0m grouped_indexers \u001b[38;5;241m=\u001b[39m \u001b[43mgroup_indexers_by_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, labels \u001b[38;5;129;01min\u001b[39;00m grouped_indexers:\n",
      "File \u001b[1;32mc:\\Users\\fitzpatrick\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xarray\\core\\indexing.py:145\u001b[0m, in \u001b[0;36mgroup_indexers_by_index\u001b[1;34m(obj, indexers, options)\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno index found for coordinate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mdims:\n\u001b[1;32m--> 145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m is not a valid dimension or coordinate for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    147\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with dimensions \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;241m.\u001b[39mdims\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    148\u001b[0m     )\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(options):\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    151\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot supply selection options \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptions\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for dimension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    152\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthat has no associated coordinate or index\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    153\u001b[0m     )\n",
      "\u001b[1;31mKeyError\u001b[0m: \"'variable' is not a valid dimension or coordinate for Dataset with dimensions FrozenMappingWarningOnValuesAccess({'Date': 0, 'lake': 4, 'type': 4})\""
     ]
    }
   ],
   "source": [
    "#lake_data = load_data([\"rnbs\",\"temp\"]).dropna(\"Date\").transpose(\"Date\", \"lake\", ...)\n",
    "lake_data = load_data([\"rnbs\", \"precip\", \"evap\", \"temp\"]).dropna(\"Date\")\n",
    "\n",
    "X, y = lake_data.sel(variable=[\"precip\", \"temp\", \"evap\"]).drop(\"type\"), lake_data.sel(\n",
    "    variable=[\"rnbs\"]).squeeze().drop([\"type\", \"variable\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'C:/Users/fitzpatrick/Desktop/Data/Input/'\n",
    "n_for = 12\n",
    "\n",
    "## Read in PCP data from CFSR\n",
    "data_1 = pd.read_csv(dir+'CFSR_APCP_Basin_Avgs.csv',sep=',')\n",
    "#data_1 = data_1.iloc[:-n_for]\n",
    "month = data_1['month']\n",
    "su_pcp = data_1['WaterSuperior']\n",
    "er_pcp = data_1['WaterErie']\n",
    "on_pcp = data_1['WaterOntario']\n",
    "mh_pcp = data_1['WaterMichigan']+data_1['WaterHuron']\n",
    "\n",
    "## Read in EVAP data from CFSR\n",
    "data_2 = pd.read_csv(dir+'CFSR_EVAP_Basin_Avgs.csv',sep=',')\n",
    "#data_2 = data_2.iloc[:-n_for]\n",
    "su_evap = data_2['WaterSuperior']\n",
    "er_evap = data_2['WaterErie']\n",
    "on_evap = data_2['WaterOntario']\n",
    "mh_evap = data_2['WaterMichigan']+data_2['WaterHuron']\n",
    "\n",
    "## Read in TMP data from CFSR\n",
    "data_3 = pd.read_csv(dir+'CFSR_TMP_Basin_Avgs.csv',sep=',')\n",
    "#data_3 = data_3.iloc[:-n_for]\n",
    "su_tmp = data_3['WaterSuperior']\n",
    "er_tmp = data_3['WaterErie']\n",
    "on_tmp = data_3['WaterOntario']\n",
    "mh_tmp = data_3['WaterMichigan']+data_3['WaterHuron']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in GLCC RNBS data\n",
    "data_4 = pd.read_csv(dir + 'rnbs_glcc.csv', sep=',')\n",
    "\n",
    "# Ensure 'Date' column is treated as string\n",
    "date_strs = data_4['Date'].astype(str)\n",
    "\n",
    "date_rnbs = []\n",
    "\n",
    "for date_str in date_strs:\n",
    "    # Insert leading zero before month\n",
    "    if len(date_str) == 6:\n",
    "        date_str = date_str[:4] + '0' + date_str[4:]\n",
    "\n",
    "    # Insert leading zero before day\n",
    "    if len(date_str) == 7:\n",
    "        date_str = date_str[:6] + '0' + date_str[6:]\n",
    "\n",
    "    # Convert to datetime object\n",
    "    datetime_obj = datetime.strptime(date_str, '%Y%m%d')\n",
    "\n",
    "    # Format the datetime object as a string in the desired format\n",
    "    date_tmp = datetime_obj.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Append formatted date to list\n",
    "    date_rnbs.append(date_tmp)\n",
    "\n",
    "# Replace the original 'Date' column with formatted dates\n",
    "data_4['Date'] = date_rnbs\n",
    "\n",
    "# Convert 'Date' column to datetime format\n",
    "data_4['Date'] = pd.to_datetime(data_4['Date'])\n",
    "\n",
    "# Add a new column 'Month' extracting month from 'Date'\n",
    "data_4['Month'] = data_4['Date'].dt.month\n",
    "\n",
    "# Select only the data that matches with the CFSR dates\n",
    "start_date = '1979-01-01'\n",
    "end_date = '2010-12-01'\n",
    "selected_data = data_4[(data_4['Date'] >= start_date) & (data_4['Date'] <= end_date)]\n",
    "\n",
    "su_rnbs = selected_data['sup']\n",
    "er_rnbs = selected_data['eri']\n",
    "on_rnbs = selected_data['ont']\n",
    "mh_rnbs = selected_data['mic_hur']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date         sup    mic_hur        eri        ont  Month\n",
      "948  1979-01-01  -20.923720   40.57140   93.83467  239.53060      1\n",
      "949  1979-02-01   33.663570   39.75065  145.70050   92.36002      2\n",
      "950  1979-03-01  139.927400  234.03050  278.34100  446.84360      3\n",
      "951  1979-04-01  177.809500  264.19100  315.27630  433.78480      4\n",
      "952  1979-05-01  250.430800  185.43650  148.65940  205.91220      5\n",
      "...         ...         ...        ...        ...        ...    ...\n",
      "1327 2010-08-01   76.175430   25.44308  -84.34577   23.81298      8\n",
      "1328 2010-09-01   74.034540   22.18228 -103.05150   23.04482      9\n",
      "1329 2010-10-01  -34.001050  -47.44791  -45.33585  116.26340     10\n",
      "1330 2010-11-01    3.796643  -13.97484  -10.20312  142.33570     11\n",
      "1331 2010-12-01  -53.290110   -2.97982    0.00000  173.69470     12\n",
      "\n",
      "[384 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(selected_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           sup_0   mic_hur_0      eri_0      ont_0       sup_1   mic_hur_1  \\\n",
      "948   -20.923720   40.571400   93.83467  239.53060   33.663570   39.750650   \n",
      "949    33.663570   39.750650  145.70050   92.36002  139.927400  234.030500   \n",
      "950   139.927400  234.030500  278.34100  446.84360  177.809500  264.191000   \n",
      "951   177.809500  264.191000  315.27630  433.78480  250.430800  185.436500   \n",
      "952   250.430800  185.436500  148.65940  205.91220  199.640200  144.628500   \n",
      "...          ...         ...        ...        ...         ...         ...   \n",
      "1315  144.831400   63.722310  -11.59754   72.83971   35.435340  -26.396920   \n",
      "1316   35.435340  -26.396920  -77.54369  -54.22311   16.346660   82.288880   \n",
      "1317   16.346660   82.288880  -55.87907   74.24047   20.565150   21.073170   \n",
      "1318   20.565150   21.073170  -36.73122   89.46812   -8.500262    1.375302   \n",
      "1319   -8.500262    1.375302   72.74823  158.28630  -39.885850    0.229217   \n",
      "\n",
      "          eri_1      ont_1       sup_2   mic_hur_2  ...     eri_10  \\\n",
      "948   145.70050   92.36002  139.927400  234.030500  ...   68.36089   \n",
      "949   278.34100  446.84360  177.809500  264.191000  ...  206.64710   \n",
      "950   315.27630  433.78480  250.430800  185.436500  ...   18.97780   \n",
      "951   148.65940  205.91220  199.640200  144.628500  ...   52.27397   \n",
      "952    93.86868   98.95717  108.214900   59.825620  ...  293.10160   \n",
      "...         ...        ...         ...         ...  ...        ...   \n",
      "1315  -77.54369  -54.22311   16.346660   82.288880  ...  142.84360   \n",
      "1316  -55.87907   74.24047   20.565150   21.073170  ...   43.22721   \n",
      "1317  -36.73122   89.46812   -8.500262    1.375302  ...  -84.34577   \n",
      "1318   72.74823  158.28630  -39.885850    0.229217  ... -103.05150   \n",
      "1319   35.84695  138.67560  -32.187100   32.918510  ...  -45.33585   \n",
      "\n",
      "          ont_10      sup_11  mic_hur_11     eri_11      ont_11      sup_12  \\\n",
      "948   103.023900  -40.866650    41.94670  206.64710  210.114500   24.519990   \n",
      "949   210.114500   24.519990    42.86357   18.97780   74.240470   -8.563540   \n",
      "950    74.240470   -8.563540    25.30259   52.27397   -3.931175    5.557864   \n",
      "951    -3.931175    5.557864    59.36719  293.10160  310.969500  135.413600   \n",
      "952   310.969500  135.413600   219.16100  226.50920  432.429300  103.310900   \n",
      "...          ...         ...         ...        ...         ...         ...   \n",
      "1315  248.070700   47.078380   104.98140   43.22721  100.855000   76.175430   \n",
      "1316  100.855000   76.175430    25.44308  -84.34577   23.812980   74.034540   \n",
      "1317   23.812980   74.034540    22.18228 -103.05150   23.044820  -34.001050   \n",
      "1318   23.044820  -34.001050   -47.44791  -45.33585  116.263400    3.796643   \n",
      "1319  116.263400    3.796643   -13.97484  -10.20312  142.335700  -53.290110   \n",
      "\n",
      "      mic_hur_12     eri_12      ont_12  \n",
      "948     42.86357   18.97780   74.240470  \n",
      "949     25.30259   52.27397   -3.931175  \n",
      "950     59.36719  293.10160  310.969500  \n",
      "951    219.16100  226.50920  432.429300  \n",
      "952    119.19280  121.24700  138.675600  \n",
      "...          ...        ...         ...  \n",
      "1315    25.44308  -84.34577   23.812980  \n",
      "1316    22.18228 -103.05150   23.044820  \n",
      "1317   -47.44791  -45.33585  116.263400  \n",
      "1318   -13.97484  -10.20312  142.335700  \n",
      "1319    -2.97982    0.00000  173.694700  \n",
      "\n",
      "[372 rows x 52 columns]\n"
     ]
    }
   ],
   "source": [
    "## This section creates a list of targets and variables going out 12 months (52 targets)\n",
    "# Define lag and forecast periods\n",
    "n_forecast = 12  # 12 months into the future\n",
    "\n",
    "# Initialize the targets DataFrame with NaN values\n",
    "targets_df = pd.DataFrame(index=selected_data.index)\n",
    "\n",
    "# Populate the targets DataFrame\n",
    "for m in range(n_forecast + 1):\n",
    "    targets_df[f'sup_{m}'] = selected_data['sup'].shift(-m)\n",
    "    targets_df[f'mic_hur_{m}'] = selected_data['mic_hur'].shift(-m)\n",
    "    targets_df[f'eri_{m}'] = selected_data['eri'].shift(-m)\n",
    "    targets_df[f'ont_{m}'] = selected_data['ont'].shift(-m)\n",
    "\n",
    "# Drop rows with NaN values\n",
    "targets_df = targets_df.dropna()\n",
    "\n",
    "print(targets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data \n",
    "# Features\n",
    "X = pd.DataFrame({\n",
    "    'su_pcp': su_pcp,\n",
    "    'er_pcp': er_pcp,\n",
    "    'on_pcp': on_pcp,\n",
    "    'mh_pcp': mh_pcp,\n",
    "    'su_evap': su_evap,\n",
    "    'er_evap': er_evap,\n",
    "    'on_evap': on_evap,\n",
    "    'mh_evap': mh_evap,\n",
    "    'su_tmp': su_tmp,\n",
    "    'er_tmp': er_tmp,\n",
    "    'on_tmp': on_tmp,\n",
    "    'mh_tmp': mh_tmp\n",
    "})\n",
    "\n",
    "# Targets\n",
    "y = pd.DataFrame({\n",
    "    'su_rnbs': su_rnbs,\n",
    "    'er_rnbs': er_rnbs,\n",
    "    'on_rnbs': on_rnbs,\n",
    "    'mh_rnbs': mh_rnbs\n",
    "})\n",
    "#y = targets_df\n",
    "\n",
    "## IF we want to include the month as a categorical feature\n",
    "# Merge on 'Month'\n",
    "#X = pd.concat([X, pd.get_dummies(month, prefix='Month')], axis=1)\n",
    "\n",
    "# Drop any rows with NaN values (if any)\n",
    "#X.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r squared value for the model is 0.5532045537319937\n",
      "Mean Squared Error: 3553.5639059802224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fitzpatrick\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:455: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__constant_value is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Process Regression\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel, ConstantKernel, RBF\n",
    "\n",
    "kernel = ConstantKernel(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))\n",
    "gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "gpr.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred, sigma = gpr.predict(X_test, return_std=True)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "print(f\"The r squared value for the model is {r_squared}\")\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r squared value for the model is 0.7512092173862659\n",
      "Mean Squared Error: 2011.782449766933\n"
     ]
    }
   ],
   "source": [
    "## Random Forest Regressor Model\n",
    "import joblib\n",
    "\n",
    "# Initialize RandomForestRegressor\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(model, 'RF_trained_model.pkl')\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "print(f\"The r squared value for the model is {r_squared}\")\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Feature  Importance\n",
      "5   er_evap    0.179492\n",
      "6   on_evap    0.170444\n",
      "7   mh_evap    0.149720\n",
      "1    er_pcp    0.127197\n",
      "2    on_pcp    0.075403\n",
      "10   on_tmp    0.056420\n",
      "4   su_evap    0.054139\n",
      "11   mh_tmp    0.047246\n",
      "3    mh_pcp    0.041353\n",
      "9    er_tmp    0.040175\n",
      "0    su_pcp    0.030408\n",
      "8    su_tmp    0.028003\n"
     ]
    }
   ],
   "source": [
    "# Get feature importances\n",
    "importances = model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Create a DataFrame to display feature importances\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "})\n",
    "\n",
    "# Sort features by importance\n",
    "feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the feature importances\n",
    "print(feature_importances_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 22022.6992 - val_loss: 14440.4834\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 20078.2402 - val_loss: 14360.1514\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 20475.2695 - val_loss: 14252.6436\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 21235.3984 - val_loss: 14106.1738\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 18602.9375 - val_loss: 13909.2842\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 20020.3105 - val_loss: 13640.3975\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 18840.4902 - val_loss: 13287.8262\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 20283.5625 - val_loss: 12829.9561\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 17526.5586 - val_loss: 12252.1631\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 16881.6836 - val_loss: 11536.4883\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 16395.7676 - val_loss: 10695.9766\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 15569.9951 - val_loss: 9728.6230\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 12642.5059 - val_loss: 8693.4463\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 11555.4941 - val_loss: 7638.1997\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9944.3770 - val_loss: 6649.1958\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8371.2051 - val_loss: 5782.8423\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6976.5229 - val_loss: 5091.0317\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5800.1323 - val_loss: 4569.5542\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5221.5635 - val_loss: 4190.6787\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4636.1196 - val_loss: 3909.1548\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4208.4648 - val_loss: 3696.3291\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4024.0942 - val_loss: 3546.8606\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3705.2239 - val_loss: 3431.9199\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3743.2698 - val_loss: 3353.2710\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3602.3159 - val_loss: 3299.8599\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3763.6362 - val_loss: 3250.2908\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3302.8315 - val_loss: 3207.1448\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3486.7781 - val_loss: 3165.8579\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3392.6182 - val_loss: 3122.9641\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3260.6418 - val_loss: 3092.4434\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3367.9075 - val_loss: 3058.9072\n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3265.9285 - val_loss: 3035.9509\n",
      "Epoch 33/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3035.8423 - val_loss: 3015.0815\n",
      "Epoch 34/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3026.9680 - val_loss: 2997.5146\n",
      "Epoch 35/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2971.0891 - val_loss: 2969.0488\n",
      "Epoch 36/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3266.1292 - val_loss: 2943.9697\n",
      "Epoch 37/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3061.3381 - val_loss: 2925.9680\n",
      "Epoch 38/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2925.1079 - val_loss: 2911.3347\n",
      "Epoch 39/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2942.6487 - val_loss: 2893.5049\n",
      "Epoch 40/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3311.2205 - val_loss: 2885.6240\n",
      "Epoch 41/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2932.1436 - val_loss: 2873.7302\n",
      "Epoch 42/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2855.0769 - val_loss: 2861.2051\n",
      "Epoch 43/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3131.3979 - val_loss: 2850.8586\n",
      "Epoch 44/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2733.6904 - val_loss: 2844.3906\n",
      "Epoch 45/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2868.9397 - val_loss: 2830.3542\n",
      "Epoch 46/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2706.2429 - val_loss: 2824.7258\n",
      "Epoch 47/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2833.2410 - val_loss: 2819.5000\n",
      "Epoch 48/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2957.3345 - val_loss: 2813.8389\n",
      "Epoch 49/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2817.3540 - val_loss: 2809.5061\n",
      "Epoch 50/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2488.1614 - val_loss: 2795.0811\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "The r squared value for the model is 0.7184963822364807\n",
      "Mean Squared Error: 2374.0131848505575\n"
     ]
    }
   ],
   "source": [
    "## Neural Network\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the neural network architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(4)  # Number of targets\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')  # Using mean squared error (mse) as the loss function\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Save the trained model\n",
    "model.save('NN_trained_model.keras')\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "print(f\"The r squared value for the model is {r_squared}\")\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
