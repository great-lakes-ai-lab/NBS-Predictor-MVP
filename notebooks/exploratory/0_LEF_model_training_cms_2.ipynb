{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training Script\n",
    "Lindsay Fitzpatrick\n",
    "ljob@umich.edu\n",
    "08/19/2024\n",
    "\n",
    "This script reads in CFSR data from 1979 - 2010 and trains different machine learning\n",
    "models to target RNBS from GLCC across the 5 Great Lakes simultaeously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel, ConstantKernel, RBF, Matern, RationalQuadratic, ExpSineSquared\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import joblib\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the directory where the CFSR and GLCC files are located\n",
    "dir = 'C:/Users/fitzpatrick/Desktop/Data/Input/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seconds_in_month(year, month):\n",
    "    # Number of days in the month\n",
    "    num_days = calendar.monthrange(year, month)[1]\n",
    "    # Convert days to seconds\n",
    "    return num_days * 24 * 60 * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_kg_to_cms_cfsr(df):\n",
    "\n",
    "    # Calculate the number of seconds for each month\n",
    "    df['seconds'] = df.apply(lambda row: seconds_in_month(int(row['year']), int(row['month'])), axis=1)\n",
    "\n",
    "    # Convert kg to meters cubed and divide by the seconds in the month\n",
    "    df['WaterErie_cms'] = (df['WaterErie'] / 1000) / df['seconds']\n",
    "    df['WaterOntario_cms'] = (df['WaterOntario'] / 1000) / df['seconds']\n",
    "    df['WaterSuperior_cms'] = (df['WaterSuperior'] / 1000) / df['seconds']\n",
    "    df['WaterMichHuron_cms'] = ((df['WaterMichigan'] + df['WaterHuron']) / 1000) / df['seconds']\n",
    "    df['LandErie_cms'] = (df['LandErie'] / 1000) / df['seconds']\n",
    "    df['LandOntario_cms'] = (df['LandOntario'] / 1000) / df['seconds']\n",
    "    df['LandSuperior_cms'] = (df['LandSuperior'] / 1000) / df['seconds']\n",
    "    df['LandMichHuron_cms'] = ((df['LandMichigan'] + df['LandHuron']) / 1000) / df['seconds']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mm_to_cms_l2(df, lake):\n",
    "\n",
    "    # Define the lake surface areas directly within the function\n",
    "    lake_sa_dict = {\n",
    "        'Superior': 82097*1000000,\n",
    "        'MichHuron': (57753 + 5956)*1000000,\n",
    "        'Erie': 25655*1000000,\n",
    "        'Ontario': 19009*1000000\n",
    "    }\n",
    "    \n",
    "    # Get the surface area for the specified lake\n",
    "    lake_sa = lake_sa_dict.get(lake, None)\n",
    "    \n",
    "    # Check if the lake surface area was found\n",
    "    if lake_sa is None:\n",
    "        raise ValueError(f\"Lake '{lake}' is not recognized. Please provide a valid lake name, either 'Superior', 'Erie', 'Ontario', or 'MichHuron'.\")\n",
    "    \n",
    "    # Calculate the number of seconds for each month\n",
    "    df['seconds'] = df.apply(lambda row: seconds_in_month(int(row['Year']), int(row['Month'])), axis=1)\n",
    "\n",
    "    # Convert millimeters to meters cubed and divide by seconds\n",
    "    df['Median_cms'] = (df['Median'] / 1000) / df['seconds'] * lake_sa\n",
    "    df['2.5_cms'] = (df['2.5 Percentile'] / 1000) / df['seconds'] * lake_sa\n",
    "    df['97.5_cms'] = (df['97.5 Percentile'] / 1000) / df['seconds'] * lake_sa\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lagged_variables(df, lags):\n",
    "    \"\"\"\n",
    "    Create lagged variables for specified columns in a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): The DataFrame containing the time series data.\n",
    "    - columns (list of str): The list of column names for which to create lagged variables.\n",
    "    - lags (int): The number of lagged variables to create.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame with the original columns and the new lagged variables.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.copy()  # To avoid modifying the original DataFrame\n",
    "    \n",
    "    for column in df.columns:\n",
    "        for lag in range(1, lags + 1):\n",
    "            df[f'{column}_lag{lag}'] = df[column].shift(lag)\n",
    "\n",
    "    # Drop rows with any NaN values\n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in PCP data from CFSR [kg]\n",
    "data_1 = pd.read_csv(dir+'CFSR_APCP_Basin_Sums.csv',sep=',')\n",
    "\n",
    "## Read in EVAP data from CFSR [kg]\n",
    "data_2 = pd.read_csv(dir+'CFSR_EVAP_Basin_Sums.csv',sep=',')\n",
    "\n",
    "## Read in TMP data from CFSR [K]\n",
    "data_3 = pd.read_csv(dir+'CFSR_TMP_Basin_Avgs.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Total Precipitation to cms\n",
    "data_1 = convert_kg_to_cms_cfsr(data_1)\n",
    "\n",
    "# Convert Total Evaporation to cms\n",
    "data_2 = convert_kg_to_cms_cfsr(data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the GLCC RNBS CSVs file in [cms]\n",
    "\n",
    "https://www.greatlakescc.org/en/coordinating-committee-products-and-datasets/#:~:text=Monthly%20Residual%20Net%20Basin%20Supplies%3A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_evap_file = pd.read_csv(dir + 'SupEvap_analysis19502022_prior19001969_1m.csv')\n",
    "sup_runoff_file = pd.read_csv(dir + 'SupRunoff_analysis19502022_prior19001969_1m.csv')\n",
    "sup_precip_file = pd.read_csv(dir + 'SupPrecip_analysis19502022_prior19001969_1m.csv')\n",
    "\n",
    "eri_evap_file = pd.read_csv(dir + 'ErieEvap_analysis19502022_prior19001969_1m.csv')\n",
    "eri_runoff_file = pd.read_csv(dir + 'ErieRunoff_analysis19502022_prior19001969_1m.csv')\n",
    "eri_precip_file = pd.read_csv(dir + 'EriePrecip_analysis19502022_prior19001969_1m.csv')\n",
    "\n",
    "ont_evap_file = pd.read_csv(dir + 'OntEvap_analysis19502022_prior19001969_1m.csv')\n",
    "ont_runoff_file = pd.read_csv(dir + 'OntRunoff_analysis19502022_prior19001969_1m.csv')\n",
    "ont_precip_file = pd.read_csv(dir + 'OntPrecip_analysis19502022_prior19001969_1m.csv')\n",
    "\n",
    "mih_evap_file = pd.read_csv(dir + 'MiHurEvap_analysis19502022_prior19001969_1m.csv')\n",
    "mih_runoff_file = pd.read_csv(dir + 'MiHurRunoff_analysis19502022_prior19001969_1m.csv')\n",
    "mih_precip_file = pd.read_csv(dir + 'MiHurPrecip_analysis19502022_prior19001969_1m.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Year  Month      Median  2.5 Percentile  97.5 Percentile\n",
      "0    1950.0    1.0   67.245050       51.865840        84.204657\n",
      "1    1950.0    2.0   35.728114       20.270061        50.587482\n",
      "2    1950.0    3.0   12.926938       -2.109247        28.563223\n",
      "3    1950.0    4.0   12.655983        3.428071        22.222697\n",
      "4    1950.0    5.0   -3.229512       -9.853121         3.477014\n",
      "..      ...    ...         ...             ...              ...\n",
      "863  2021.0   12.0  112.903571       99.068128       126.926402\n",
      "864  2022.0    1.0  139.083649      125.006839       153.776202\n",
      "865  2022.0    2.0   68.063946       54.649119        81.100302\n",
      "866  2022.0    3.0   39.705374       26.086656        53.065299\n",
      "867  2022.0    4.0   12.252169        3.359856        21.576276\n",
      "\n",
      "[868 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(sup_evap_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_evap = convert_mm_to_cms_l2(sup_evap_file, 'Superior')\n",
    "sup_runoff = convert_mm_to_cms_l2(sup_runoff_file, 'Superior')\n",
    "sup_precip = convert_mm_to_cms_l2(sup_precip_file, 'Superior')\n",
    "\n",
    "eri_evap = convert_mm_to_cms_l2(eri_evap_file, 'Erie')\n",
    "eri_runoff = convert_mm_to_cms_l2(eri_runoff_file, 'Erie')\n",
    "eri_precip = convert_mm_to_cms_l2(eri_precip_file, 'Erie')\n",
    "\n",
    "ont_evap = convert_mm_to_cms_l2(ont_evap_file, 'Ontario')\n",
    "ont_runoff = convert_mm_to_cms_l2(ont_runoff_file, 'Ontario')\n",
    "ont_precip = convert_mm_to_cms_l2(ont_precip_file, 'Ontario')\n",
    "\n",
    "mih_evap = convert_mm_to_cms_l2(mih_evap_file, 'MichHuron')\n",
    "mih_runoff = convert_mm_to_cms_l2(mih_runoff_file, 'MichHuron')\n",
    "mih_precip = convert_mm_to_cms_l2(mih_precip_file, 'MichHuron')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we prepare the data for training and testing. We set the features 'X' as total over lake\n",
    "precipitation, total over lake evaporation, and the average air temperature over each lake. The\n",
    "targets 'y' are RNBS for each lake simultaeously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features\n",
    "X = pd.DataFrame({\n",
    "    'su_pcp_w': data_1['WaterSuperior_cms'],\n",
    "    'er_pcp_w': data_1['WaterErie_cms'],\n",
    "    'on_pcp_w': data_1['WaterOntario_cms'],\n",
    "    'mh_pcp_w': data_1['WaterMichHuron_cms'], #data_1['WaterMichigan']+data_1['WaterHuron'], # add the sums\n",
    "    'su_pcp_l': data_1['LandSuperior_cms'],\n",
    "    'er_pcp_l': data_1['LandErie_cms'],\n",
    "    'on_pcp_l': data_1['LandOntario_cms'],\n",
    "    'mh_pcp_l': data_1['LandMichHuron_cms'],\n",
    "    'su_evap_w': data_2['WaterSuperior_cms'],\n",
    "    'er_evap_w': data_2['WaterErie_cms'],\n",
    "    'on_evap_w': data_2['WaterOntario_cms'],\n",
    "    'mh_evap_w': data_2['WaterMichHuron_cms'], #data_2['WaterMichigan']+data_2['WaterHuron'], # add the sums\n",
    "    'su_evap_l': data_2['LandSuperior_cms'],\n",
    "    'er_evap_l': data_2['LandErie_cms'],\n",
    "    'on_evap_l': data_2['LandOntario_cms'],\n",
    "    'mh_evap_l': data_2['LandMichHuron_cms'],\n",
    "    'su_tmp_w': data_3['WaterSuperior'],\n",
    "    'er_tmp_w': data_3['WaterErie'],\n",
    "    'on_tmp_w': data_3['WaterOntario'],\n",
    "    'mh_tmp_w': (data_3['WaterMichigan']+data_3['WaterHuron'])/2,\n",
    "    'su_tmp_l': data_3['LandSuperior'],\n",
    "    'er_tmp_l': data_3['LandErie'],\n",
    "    'on_tmp_l': data_3['LandOntario'],\n",
    "    'mh_tmp_l': (data_3['LandMichigan']+data_3['LandHuron'])/2 # take the average temp\n",
    "})\n",
    "\n",
    "# Set the index by date\n",
    "X.set_index(pd.to_datetime(data_1[['year', 'month']].assign(day=1)), inplace=True)\n",
    "\n",
    "# Targets are the components of NBS (P, E, R)\n",
    "targets = pd.DataFrame({\n",
    "    'su_evap_y': sup_evap['Median_cms'],\n",
    "    'su_precip': sup_precip['Median_cms'],\n",
    "    'su_runoff': sup_runoff['Median_cms'],\n",
    "    'er_evap_y': eri_evap['Median_cms'],\n",
    "    'er_precip': eri_precip['Median_cms'],\n",
    "    'er_runoff': eri_runoff['Median_cms'],\n",
    "    'on_evap_y': ont_evap['Median_cms'],\n",
    "    'on_precip': ont_precip['Median_cms'],\n",
    "    'on_runoff': ont_runoff['Median_cms'],\n",
    "    'mh_evap_y': mih_evap['Median_cms'],\n",
    "    'mh_precip': mih_precip['Median_cms'],\n",
    "    'mh_runoff': mih_runoff['Median_cms'],\n",
    "})\n",
    "\n",
    "# Set the index of the targets\n",
    "targets.set_index(pd.to_datetime(eri_evap[['Year', 'Month']].assign(day=1)), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               su_pcp_w    er_pcp_w    on_pcp_w     mh_pcp_w     su_pcp_l  \\\n",
      "1979-02-01  1725.202776  307.523427  174.595630  1647.644403  2994.613464   \n",
      "1979-03-01  2985.410905  502.023507  216.720716  3366.383104  6179.396933   \n",
      "1979-04-01  1833.850353  771.898492  361.687857  3439.840263  3900.078255   \n",
      "1979-05-01  2518.523016  599.135634  264.458043  2364.981209  5220.389769   \n",
      "1979-06-01  2927.137756  395.267754  202.659087  1864.819393  5602.199907   \n",
      "...                 ...         ...         ...          ...          ...   \n",
      "2010-08-01  1537.159708  156.390801  133.331169  1160.518649  3422.201604   \n",
      "2010-09-01  2935.872420  281.306113  243.609570  2866.455046  7201.816009   \n",
      "2010-10-01  1620.451353  390.675933  200.661594  1651.151799  3658.468471   \n",
      "2010-11-01  2178.428373  477.138485  278.313391  2092.985524  4640.400044   \n",
      "2010-12-01  1106.622457  311.816611  284.541208  2060.855935  2527.814144   \n",
      "\n",
      "               er_pcp_l     on_pcp_l      mh_pcp_l    su_evap_w   er_evap_w  \\\n",
      "1979-02-01  1833.651418  1848.508659   4599.198067  1206.368877  185.093925   \n",
      "1979-03-01  3122.718302  2168.768074  12369.684681   687.058922   51.106576   \n",
      "1979-04-01  4203.192412  3347.040605  10925.668866   339.531752   85.201176   \n",
      "1979-05-01  3569.127451  2594.097601   9747.586888   -25.832286  110.579591   \n",
      "1979-06-01  2959.050909  2041.493178   8656.297711  -266.550944  157.268096   \n",
      "...                 ...          ...           ...          ...         ...   \n",
      "2010-08-01   830.806721  2028.928838   4696.342518   663.180124  359.738536   \n",
      "2010-09-01  1571.877797  2885.989172  10068.495380  1048.561240  442.253856   \n",
      "2010-10-01  1775.198627  2299.525719   5910.038960  1275.570387  418.297569   \n",
      "2010-11-01  3236.291721  2539.089961   6993.751048  1505.226102  291.818125   \n",
      "2010-12-01  1740.726215  2638.480677   6145.291828  1981.464961  326.894299   \n",
      "\n",
      "            ...  on_evap_l_lag1  mh_evap_l_lag1  su_tmp_w_lag1  er_tmp_w_lag1  \\\n",
      "1979-02-01  ...      921.807095     2252.984922          262.3          267.6   \n",
      "1979-03-01  ...      882.614321     2023.052319          261.6          265.1   \n",
      "1979-04-01  ...      726.316907     2980.383207          268.5          273.4   \n",
      "1979-05-01  ...     1157.422723     4247.412089          272.5          276.9   \n",
      "1979-06-01  ...     1676.184313     7073.202234          276.7          282.0   \n",
      "...         ...             ...             ...            ...            ...   \n",
      "2010-08-01  ...     2436.021762    11413.671448          289.5          296.9   \n",
      "2010-09-01  ...     2002.362217     8347.277000          291.1          296.4   \n",
      "2010-10-01  ...     1607.903419     5708.697804          284.7          291.4   \n",
      "2010-11-01  ...     1405.537535     4131.552359          281.9          286.0   \n",
      "2010-12-01  ...     1065.453413     3238.565015          276.0          279.8   \n",
      "\n",
      "            on_tmp_w_lag1  mh_tmp_w_lag1  su_tmp_l_lag1  er_tmp_l_lag1  \\\n",
      "1979-02-01          267.7         265.95          255.1          265.7   \n",
      "1979-03-01          263.0         264.15          255.9          263.5   \n",
      "1979-04-01          274.6         271.70          266.1          274.4   \n",
      "1979-05-01          277.5         275.50          271.4          277.9   \n",
      "1979-06-01          283.3         279.95          278.4          284.9   \n",
      "...                   ...            ...            ...            ...   \n",
      "2010-08-01          295.4         293.80          291.7          296.2   \n",
      "2010-09-01          295.1         294.45          291.7          295.8   \n",
      "2010-10-01          290.5         288.80          283.2          290.7   \n",
      "2010-11-01          284.8         284.65          279.5          285.0   \n",
      "2010-12-01          278.6         278.60          272.6          278.0   \n",
      "\n",
      "            on_tmp_l_lag1  mh_tmp_l_lag1  \n",
      "1979-02-01          265.6         262.00  \n",
      "1979-03-01          260.4         259.80  \n",
      "1979-04-01          274.0         270.65  \n",
      "1979-05-01          277.7         275.25  \n",
      "1979-06-01          284.5         281.80  \n",
      "...                   ...            ...  \n",
      "2010-08-01          294.7         294.05  \n",
      "2010-09-01          293.7         294.00  \n",
      "2010-10-01          289.1         287.30  \n",
      "2010-11-01          282.8         282.50  \n",
      "2010-12-01          276.5         275.80  \n",
      "\n",
      "[383 rows x 48 columns]\n"
     ]
    }
   ],
   "source": [
    "lagged_X = create_lagged_variables(X, lags=1)\n",
    "print (lagged_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               su_pcp_w    er_pcp_w    on_pcp_w     mh_pcp_w     su_pcp_l  \\\n",
      "1979-01-01  1418.815517  480.493648  435.053300  2731.419734  1908.337758   \n",
      "1979-02-01  1725.202776  307.523427  174.595630  1647.644403  2994.613464   \n",
      "1979-03-01  2985.410905  502.023507  216.720716  3366.383104  6179.396933   \n",
      "1979-04-01  1833.850353  771.898492  361.687857  3439.840263  3900.078255   \n",
      "1979-05-01  2518.523016  599.135634  264.458043  2364.981209  5220.389769   \n",
      "...                 ...         ...         ...          ...          ...   \n",
      "2010-08-01  1537.159708  156.390801  133.331169  1160.518649  3422.201604   \n",
      "2010-09-01  2935.872420  281.306113  243.609570  2866.455046  7201.816009   \n",
      "2010-10-01  1620.451353  390.675933  200.661594  1651.151799  3658.468471   \n",
      "2010-11-01  2178.428373  477.138485  278.313391  2092.985524  4640.400044   \n",
      "2010-12-01  1106.622457  311.816611  284.541208  2060.855935  2527.814144   \n",
      "\n",
      "               er_pcp_l     on_pcp_l      mh_pcp_l    su_evap_w   er_evap_w  \\\n",
      "1979-01-01  2667.669705  3916.176779   8036.334636  2221.948656  197.307398   \n",
      "1979-02-01  1833.651418  1848.508659   4599.198067  1206.368877  185.093925   \n",
      "1979-03-01  3122.718302  2168.768074  12369.684681   687.058922   51.106576   \n",
      "1979-04-01  4203.192412  3347.040605  10925.668866   339.531752   85.201176   \n",
      "1979-05-01  3569.127451  2594.097601   9747.586888   -25.832286  110.579591   \n",
      "...                 ...          ...           ...          ...         ...   \n",
      "2010-08-01   830.806721  2028.928838   4696.342518   663.180124  359.738536   \n",
      "2010-09-01  1571.877797  2885.989172  10068.495380  1048.561240  442.253856   \n",
      "2010-10-01  1775.198627  2299.525719   5910.038960  1275.570387  418.297569   \n",
      "2010-11-01  3236.291721  2539.089961   6993.751048  1505.226102  291.818125   \n",
      "2010-12-01  1740.726215  2638.480677   6145.291828  1981.464961  326.894299   \n",
      "\n",
      "            ...    on_evap_l    mh_evap_l  su_tmp_w  er_tmp_w  on_tmp_w  \\\n",
      "1979-01-01  ...   921.807095  2252.984922     262.3     267.6     267.7   \n",
      "1979-02-01  ...   882.614321  2023.052319     261.6     265.1     263.0   \n",
      "1979-03-01  ...   726.316907  2980.383207     268.5     273.4     274.6   \n",
      "1979-04-01  ...  1157.422723  4247.412089     272.5     276.9     277.5   \n",
      "1979-05-01  ...  1676.184313  7073.202234     276.7     282.0     283.3   \n",
      "...         ...          ...          ...       ...       ...       ...   \n",
      "2010-08-01  ...  2002.362217  8347.277000     291.1     296.4     295.1   \n",
      "2010-09-01  ...  1607.903419  5708.697804     284.7     291.4     290.5   \n",
      "2010-10-01  ...  1405.537535  4131.552359     281.9     286.0     284.8   \n",
      "2010-11-01  ...  1065.453413  3238.565015     276.0     279.8     278.6   \n",
      "2010-12-01  ...  1208.969958  3154.227079     269.0     271.2     270.8   \n",
      "\n",
      "            mh_tmp_w  su_tmp_l  er_tmp_l  on_tmp_l  mh_tmp_l  \n",
      "1979-01-01    265.95     255.1     265.7     265.6    262.00  \n",
      "1979-02-01    264.15     255.9     263.5     260.4    259.80  \n",
      "1979-03-01    271.70     266.1     274.4     274.0    270.65  \n",
      "1979-04-01    275.50     271.4     277.9     277.7    275.25  \n",
      "1979-05-01    279.95     278.4     284.9     284.5    281.80  \n",
      "...              ...       ...       ...       ...       ...  \n",
      "2010-08-01    294.45     291.7     295.8     293.7    294.00  \n",
      "2010-09-01    288.80     283.2     290.7     289.1    287.30  \n",
      "2010-10-01    284.65     279.5     285.0     282.8    282.50  \n",
      "2010-11-01    278.60     272.6     278.0     276.5    275.80  \n",
      "2010-12-01    270.95     264.5     269.4     268.6    267.95  \n",
      "\n",
      "[384 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge the features and targets to align with the dates\n",
    "# Drops the dates where we don't have CFS data \n",
    "merged_df = pd.merge(lagged_X, targets, left_index=True, right_index=True, how='inner')\n",
    "\n",
    "# Pull the target variables back out \n",
    "y = merged_df[['su_evap_y', 'su_precip', 'su_runoff', 'er_evap_y', 'er_precip', 'er_runoff',\n",
    "               'on_evap_y', 'on_precip', 'on_runoff', 'mh_evap_y', 'mh_precip', 'mh_runoff']]\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and testing data sets. We could do it as a random 80/20 split\n",
    "but instead we set split the data set by date ranges. This can easily be adjusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(lagged_X, y, test_size=0.2, random_state=42)\n",
    "#train_start_date = '1979-01-01'\n",
    "#train_end_date = '2004-12-01'\n",
    "# Testing dataset\n",
    "#val_start_date = '2005-01-01'\n",
    "#val_end_date = '2011-01-01'\n",
    "\n",
    "#X_train = X[train_start_date:train_end_date]\n",
    "#y_train = y[train_start_date:train_end_date]\n",
    "#X_test = X[val_start_date:val_end_date]\n",
    "#y_test = y[val_start_date:val_end_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (306, 48)\n",
      "Shape of y_train: (306, 12)\n",
      "Shape of X_test: (77, 48)\n",
      "Shape of y_test: (77, 12)\n"
     ]
    }
   ],
   "source": [
    "# Verify shapes\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is best practice to standardize the data from 0-1 before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306, 48)\n",
      "(77, 48)\n"
     ]
    }
   ],
   "source": [
    "# Standardize the data\n",
    "x_scaler = StandardScaler()\n",
    "y_scaler = StandardScaler()\n",
    "X_train_scaled = x_scaler.fit_transform(X_train)\n",
    "X_test_scaled = x_scaler.fit_transform(X_test)\n",
    "y_train_scaled = y_scaler.fit_transform(y_train)\n",
    "y_test_scaled = y_scaler.fit_transform(y_test)\n",
    "\n",
    "print(X_train_scaled.shape)\n",
    "print(X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Below we train different models using the same data and calculate the r squared values on the \n",
    "test data to compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r squared value for the model is 0.8083878321974806\n",
      "Mean Squared Error: 0.1916121678025194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fitzpatrick\\AppData\\Local\\miniconda3\\envs\\mvpenv\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\fitzpatrick\\AppData\\Local\\miniconda3\\envs\\mvpenv\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Testing Different Kernels\n",
    "# Basic kernel using ConstantKernel: r2 = 0.8259\n",
    "#kernel = ConstantKernel(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))\n",
    "\n",
    "# Matt's optimal kernel: r2 = 0.8321\n",
    "#kernel = 1.0 * Matern(nu=1.5) * RationalQuadratic()\n",
    "\n",
    "# Test to add a seasonality component: r2 = 0.8279\n",
    "#period = 3.0  # Period of the season\n",
    "#kernel = ConstantKernel(1.0, (1e-3, 1e3)) * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2)) + ExpSineSquared(length_scale=1.0, periodicity=period, periodicity_bounds=(1e-2, 1e2))\n",
    "\n",
    "#kernel = 1.0 * ExpSineSquared(periodicity=12)\n",
    "\n",
    "kernel = 1.0 * RBF() + 1.0 * Matern(nu=2.5) + 1.0 * RationalQuadratic()\n",
    "\n",
    "# Set up the model\n",
    "gpr = GaussianProcessRegressor(kernel=kernel, alpha=0.1, n_restarts_optimizer=10, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "gpr.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Save the trained model\n",
    "#joblib.dump(gpr, 'GP_trained_model.joblib')\n",
    "#joblib.dump(x_scaler, 'x_scaler.joblib')\n",
    "#joblib.dump(y_scaler, 'y_scaler.joblib')\n",
    "\n",
    "# Predictions\n",
    "y_pred, sigma = gpr.predict(X_test_scaled, return_std=True)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test_scaled, y_pred)\n",
    "r_squared = r2_score(y_test_scaled, y_pred)\n",
    "print(f\"The r squared value for the model is {r_squared}\")\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r squared value for the model is 0.6781358056116463\n",
      "Mean Squared Error: 106837.73060150853\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestRegressor' object has no attribute 'coef_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m feature_names \u001b[38;5;241m=\u001b[39m lagged_X\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Get coefficients\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m coefficients \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef_\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Create a DataFrame for better visualization\u001b[39;00m\n\u001b[0;32m     28\u001b[0m importance_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m'\u001b[39m: feature_names,\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCoefficient\u001b[39m\u001b[38;5;124m'\u001b[39m: coefficients\n\u001b[0;32m     31\u001b[0m })\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RandomForestRegressor' object has no attribute 'coef_'"
     ]
    }
   ],
   "source": [
    "## Random Forest Regressor Model: r2 = 0.7389\n",
    "\n",
    "# Initialize RandomForestRegressor\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(model, 'RF_trained_model.joblib')\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "print(f\"The r squared value for the model is {r_squared}\")\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r squared value for the model is 0.776036270114854\n",
      "Mean Squared Error: 78431.12444419645\n",
      "        Target         Feature  Coefficient  Absolute Importance\n",
      "0    su_evap_y   on_tmp_w_lag1  -286.617750           286.617750\n",
      "1    su_evap_y   er_tmp_w_lag1   189.563720           189.563720\n",
      "2    su_evap_y   on_tmp_l_lag1   180.238058           180.238058\n",
      "3    su_evap_y   er_tmp_l_lag1  -135.715438           135.715438\n",
      "4    su_evap_y        er_tmp_w   -90.550113            90.550113\n",
      "..         ...             ...          ...                  ...\n",
      "571  mh_runoff  mh_evap_l_lag1    -0.044336             0.044336\n",
      "572  mh_runoff   su_pcp_w_lag1    -0.042586             0.042586\n",
      "573  mh_runoff   er_pcp_l_lag1     0.035229             0.035229\n",
      "574  mh_runoff   su_pcp_l_lag1     0.004302             0.004302\n",
      "575  mh_runoff       on_evap_l    -0.001247             0.001247\n",
      "\n",
      "[576 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "## Linear Regression Model \n",
    "\n",
    "# Initialize Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(model, 'LR_trained_model.joblib')\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "print(f\"The r squared value for the model is {r_squared}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Get feature names from the DataFrame\n",
    "feature_names = lagged_X.columns\n",
    "\n",
    "# Get coefficients\n",
    "coefficients = model.coef_\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "importance_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through each target variable and store its coefficients\n",
    "for i, target in enumerate(y.columns):\n",
    "    target_importance_df = pd.DataFrame({\n",
    "        'Feature': lagged_X.columns,\n",
    "        'Coefficient': coefficients[i]  # Get coefficients for the i-th target\n",
    "    })\n",
    "    target_importance_df['Absolute Importance'] = target_importance_df['Coefficient'].abs()\n",
    "    target_importance_df = target_importance_df.sort_values(by='Absolute Importance', ascending=False)\n",
    "    target_importance_df['Target'] = target  # Add the target variable name\n",
    "    importance_df = pd.concat([importance_df, target_importance_df], ignore_index=True)\n",
    "\n",
    "# Print ranked features for each target\n",
    "print(importance_df[['Target', 'Feature', 'Coefficient', 'Absolute Importance']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1869960.5000 - val_loss: 1924885.3750\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1916225.1250 - val_loss: 1924183.1250\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1858305.2500 - val_loss: 1923263.7500\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1906919.0000 - val_loss: 1921910.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1808742.3750 - val_loss: 1919836.3750\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1861943.6250 - val_loss: 1916625.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1873305.7500 - val_loss: 1911846.3750\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1854955.8750 - val_loss: 1904934.8750\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1896222.6250 - val_loss: 1895153.1250\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1842323.7500 - val_loss: 1881833.7500\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1802505.0000 - val_loss: 1864042.8750\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1803972.6250 - val_loss: 1841202.2500\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1701257.5000 - val_loss: 1812269.7500\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1720719.5000 - val_loss: 1776936.0000\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1680347.5000 - val_loss: 1734519.5000\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1627102.5000 - val_loss: 1685280.0000\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1623607.1250 - val_loss: 1628864.3750\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1520199.2500 - val_loss: 1566244.5000\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1471702.2500 - val_loss: 1498035.2500\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1420987.3750 - val_loss: 1425724.3750\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1287188.7500 - val_loss: 1352386.7500\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1285477.0000 - val_loss: 1277815.8750\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1192841.2500 - val_loss: 1205003.7500\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1146630.0000 - val_loss: 1136076.5000\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1036167.4375 - val_loss: 1073362.5000\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 984313.4375 - val_loss: 1016625.0000\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 955366.3125 - val_loss: 965587.9375\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 873727.8125 - val_loss: 921142.1875\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 863150.5000 - val_loss: 882647.5000\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 851816.3125 - val_loss: 849597.1875\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 765737.9375 - val_loss: 821181.6875\n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 739976.6250 - val_loss: 796817.7500\n",
      "Epoch 33/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 766755.8125 - val_loss: 775108.7500\n",
      "Epoch 34/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 724459.3125 - val_loss: 756846.8750\n",
      "Epoch 35/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 706804.5625 - val_loss: 741267.8125\n",
      "Epoch 36/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 729386.1875 - val_loss: 726729.6875\n",
      "Epoch 37/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 684470.3125 - val_loss: 714582.1875\n",
      "Epoch 38/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 705821.1250 - val_loss: 703541.0625\n",
      "Epoch 39/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 659861.1875 - val_loss: 693983.8750\n",
      "Epoch 40/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 680585.8125 - val_loss: 684687.8750\n",
      "Epoch 41/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 677535.5000 - val_loss: 675804.2500\n",
      "Epoch 42/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 638788.9375 - val_loss: 667831.3750\n",
      "Epoch 43/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 617241.3125 - val_loss: 660720.3125\n",
      "Epoch 44/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 634804.5000 - val_loss: 653726.8750\n",
      "Epoch 45/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 631810.1875 - val_loss: 647367.1250\n",
      "Epoch 46/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 637037.0625 - val_loss: 640872.4375\n",
      "Epoch 47/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 616633.8125 - val_loss: 634838.7500\n",
      "Epoch 48/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 617893.5625 - val_loss: 628957.0625\n",
      "Epoch 49/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 627797.6875 - val_loss: 622992.8750\n",
      "Epoch 50/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 583975.1250 - val_loss: 617339.0000\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "The r squared value for the model is -0.15938745439052582\n",
      "Mean Squared Error: 602626.7667079141\n"
     ]
    }
   ],
   "source": [
    "## Neural Network: r2 = 0.4002\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the neural network architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(12)  # Number of targets\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')  # Using mean squared error (mse) as the loss function\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(model,'NN_trained_model.joblib')\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "print(f\"The r squared value for the model is {r_squared}\")\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
