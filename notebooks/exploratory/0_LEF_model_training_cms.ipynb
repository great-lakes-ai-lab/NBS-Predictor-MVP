{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training Script\n",
    "Lindsay Fitzpatrick\n",
    "ljob@umich.edu\n",
    "08/19/2024\n",
    "\n",
    "This script reads in CFSR data from 1979 - 2010 and trains different machine learning\n",
    "models to target RNBS from GLCC across the 5 Great Lakes simultaeously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel, ConstantKernel, RBF, Matern, RationalQuadratic\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the directory where the CFSR and GLCC files are located\n",
    "dir = 'C:/Users/fitzpatrick/Desktop/Data/Input/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seconds_in_month(year, month):\n",
    "    # Number of days in the month\n",
    "    num_days = calendar.monthrange(year, month)[1]\n",
    "    # Convert days to seconds\n",
    "    return num_days * 24 * 60 * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_kg_to_cms_cfsr(df):\n",
    "\n",
    "    # Calculate the number of seconds for each month\n",
    "    df['seconds'] = df.apply(lambda row: seconds_in_month(int(row['year']), int(row['month'])), axis=1)\n",
    "\n",
    "    # Convert kg to meters cubed and divide by the seconds in the month\n",
    "    df['WaterErie_m3'] = (df['WaterErie'] / 1000) / df['seconds']\n",
    "    df['WaterOntario_m3'] = (df['WaterOntario'] / 1000) / df['seconds']\n",
    "    df['WaterSuperior_m3'] = (df['WaterSuperior'] / 1000) / df['seconds']\n",
    "    df['WaterMichHuron_m3'] = ((df['WaterMichigan'] + df['WaterHuron']) / 1000) / df['seconds']\n",
    "\n",
    "    # Convert the data to cubic meters per second\n",
    "    #df['WaterErie_cms'] = df['WaterErie_m3'] / df['seconds']\n",
    "    #df['WaterOntario_cms'] = df['WaterOntario_m3'] / df['seconds']\n",
    "    #df['WaterSuperior_cms'] = df['WaterSuperior_m3'] / df['seconds']\n",
    "    #df['WaterMichHuron_cms'] = df['WaterMichHuron_m3'] / df['seconds']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mm_to_cms_l2(df, lake):\n",
    "\n",
    "    # Define the lake surface areas directly within the function\n",
    "    lake_sa_dict = {\n",
    "        'Superior': 82097*1000000,\n",
    "        'MichHuron': (57753 + 5956)*1000000,\n",
    "        'Erie': 25655*1000000,\n",
    "        'Ontario': 19009*1000000\n",
    "    }\n",
    "    \n",
    "    # Get the surface area for the specified lake\n",
    "    lake_sa = lake_sa_dict.get(lake, None)\n",
    "    \n",
    "    # Check if the lake surface area was found\n",
    "    if lake_sa is None:\n",
    "        raise ValueError(f\"Lake '{lake}' is not recognized. Please provide a valid lake name, either 'Superior', 'Erie', 'Ontario', or 'MichHuron'.\")\n",
    "    \n",
    "    # Calculate the number of seconds for each month\n",
    "    df['seconds'] = df.apply(lambda row: seconds_in_month(int(row['Year']), int(row['Month'])), axis=1)\n",
    "\n",
    "    # Convert millimeters to meters cubed and divide by seconds\n",
    "    df['Median_cms'] = (df['Median'] / 1000) / df['seconds'] * lake_sa\n",
    "    df['2.5_cms'] = (df['2.5 Percentile'] / 1000) / df['seconds'] * lake_sa\n",
    "    df['97.5_cms'] = (df['97.5 Percentile'] / 1000) / df['seconds'] * lake_sa\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in PCP data from CFSR [kg]\n",
    "data_1 = pd.read_csv(dir+'CFSR_APCP_Basin_Sums.csv',sep=',')\n",
    "\n",
    "## Read in EVAP data from CFSR [kg]\n",
    "data_2 = pd.read_csv(dir+'CFSR_EVAP_Basin_Sums.csv',sep=',')\n",
    "\n",
    "## Read in TMP data from CFSR [K]\n",
    "data_3 = pd.read_csv(dir+'CFSR_TMP_Basin_Avgs.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     year  month     BasinErie     WaterErie      LandErie  BasinOntario  \\\n",
      "0    1979      1  1.869364e+12  1.286954e+12  7.145087e+12  1.032279e+13   \n",
      "1    1979      2  1.102083e+12  7.439607e+11  4.435970e+12  4.059830e+12   \n",
      "2    1979      3  2.140239e+12  1.344620e+12  8.363889e+12  5.413565e+12   \n",
      "3    1979      4  2.926690e+12  2.000761e+12  1.089467e+13  8.373868e+12   \n",
      "4    1979      5  2.524354e+12  1.604725e+12  9.559551e+12  6.477845e+12   \n",
      "..    ...    ...           ...           ...           ...           ...   \n",
      "379  2010      8  5.752132e+11  4.188771e+11  2.225233e+12  4.348570e+12   \n",
      "380  2010      9  1.088025e+12  7.291454e+11  4.074307e+12  6.778341e+12   \n",
      "381  2010     10  1.371390e+12  1.046386e+12  4.754692e+12  5.580925e+12   \n",
      "382  2010     11  2.093816e+12  1.236743e+12  8.388468e+12  6.453425e+12   \n",
      "383  2010     12  1.213677e+12  8.351696e+11  4.662361e+12  6.970965e+12   \n",
      "\n",
      "     WaterOntario   LandOntario    BasinHuron    WaterHuron  ...  \\\n",
      "0    1.165247e+12  1.048909e+13  1.579960e+13  3.439931e+12  ...   \n",
      "1    4.223817e+11  4.471912e+12  8.450088e+12  1.975324e+12  ...   \n",
      "2    5.804648e+11  5.808828e+12  2.132413e+13  3.811726e+12  ...   \n",
      "3    9.374949e+11  8.675529e+12  2.166704e+13  4.774123e+12  ...   \n",
      "4    7.083244e+11  6.948031e+12  1.738593e+13  3.492884e+12  ...   \n",
      "..            ...           ...           ...           ...  ...   \n",
      "379  3.571142e+11  5.434283e+12  9.422947e+12  1.661288e+12  ...   \n",
      "380  6.314360e+11  7.480484e+12  2.023142e+13  4.074341e+12  ...   \n",
      "381  5.374520e+11  6.159050e+12  1.149048e+13  2.318071e+12  ...   \n",
      "382  7.213883e+11  6.581321e+12  1.358179e+13  3.004914e+12  ...   \n",
      "383  7.621152e+11  7.066907e+12  1.171868e+13  2.605568e+12  ...   \n",
      "\n",
      "     LandSuperior  seconds  WaterErie_m3  WaterOntario_m3  WaterSuperior_m3  \\\n",
      "0    5.111292e+12  2678400  1.286954e+09     1.165247e+09      3.800155e+09   \n",
      "1    7.244569e+12  2419200  7.439607e+08     4.223817e+08      4.173611e+09   \n",
      "2    1.655090e+13  2678400  1.344620e+09     5.804648e+08      7.996125e+09   \n",
      "3    1.010900e+13  2592000  2.000761e+09     9.374949e+08      4.753340e+09   \n",
      "4    1.398229e+13  2678400  1.604725e+09     7.083244e+08      6.745612e+09   \n",
      "..            ...      ...           ...              ...               ...   \n",
      "379  9.166025e+12  2678400  4.188771e+08     3.571142e+08      4.117129e+09   \n",
      "380  1.866711e+13  2592000  7.291454e+08     6.314360e+08      7.609781e+09   \n",
      "381  9.798842e+12  2678400  1.046386e+09     5.374520e+08      4.340217e+09   \n",
      "382  1.202792e+13  2592000  1.236743e+09     7.213883e+08      5.646486e+09   \n",
      "383  6.770497e+12  2678400  8.351696e+08     7.621152e+08      2.963978e+09   \n",
      "\n",
      "     WaterMichHuron_m3  WaterErie_cms  WaterOntario_cms  WaterSuperior_cms  \\\n",
      "0         7.315835e+09     480.493648        435.053300        1418.815517   \n",
      "1         3.985981e+09     307.523427        174.595630        1725.202776   \n",
      "2         9.016521e+09     502.023507        216.720716        2985.410905   \n",
      "3         8.916066e+09     771.898492        361.687857        1833.850353   \n",
      "4         6.334366e+09     599.135634        264.458043        2518.523016   \n",
      "..                 ...            ...               ...                ...   \n",
      "379       3.108333e+09     156.390801        133.331169        1537.159708   \n",
      "380       7.429851e+09     281.306113        243.609570        2935.872420   \n",
      "381       4.422445e+09     390.675933        200.661594        1620.451353   \n",
      "382       5.425018e+09     477.138485        278.313391        2178.428373   \n",
      "383       5.519797e+09     311.816611        284.541208        1106.622457   \n",
      "\n",
      "     WaterMichHuron_cms  \n",
      "0           2731.419734  \n",
      "1           1647.644403  \n",
      "2           3366.383104  \n",
      "3           3439.840263  \n",
      "4           2364.981209  \n",
      "..                  ...  \n",
      "379         1160.518649  \n",
      "380         2866.455046  \n",
      "381         1651.151799  \n",
      "382         2092.985524  \n",
      "383         2060.855935  \n",
      "\n",
      "[384 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert Total Precipitation to cms\n",
    "data_1 = convert_kg_to_cms_cfsr(data_1)\n",
    "\n",
    "# Convert Total Evaporation to cms\n",
    "data_2 = convert_kg_to_cms_cfsr(data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the GLCC RNBS CSVs file in [cms]\n",
    "\n",
    "https://www.greatlakescc.org/en/coordinating-committee-products-and-datasets/#:~:text=Monthly%20Residual%20Net%20Basin%20Supplies%3A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_evap_file = pd.read_csv(dir + 'SupEvap_analysis19502022_prior19001969_1m.csv')\n",
    "sup_runoff_file = pd.read_csv(dir + 'SupRunoff_analysis19502022_prior19001969_1m.csv')\n",
    "sup_precip_file = pd.read_csv(dir + 'SupPrecip_analysis19502022_prior19001969_1m.csv')\n",
    "\n",
    "eri_evap_file = pd.read_csv(dir + 'ErieEvap_analysis19502022_prior19001969_1m.csv')\n",
    "eri_runoff_file = pd.read_csv(dir + 'ErieRunoff_analysis19502022_prior19001969_1m.csv')\n",
    "eri_precip_file = pd.read_csv(dir + 'EriePrecip_analysis19502022_prior19001969_1m.csv')\n",
    "\n",
    "ont_evap_file = pd.read_csv(dir + 'OntEvap_analysis19502022_prior19001969_1m.csv')\n",
    "ont_runoff_file = pd.read_csv(dir + 'OntRunoff_analysis19502022_prior19001969_1m.csv')\n",
    "ont_precip_file = pd.read_csv(dir + 'OntPrecip_analysis19502022_prior19001969_1m.csv')\n",
    "\n",
    "mih_evap_file = pd.read_csv(dir + 'MiHurEvap_analysis19502022_prior19001969_1m.csv')\n",
    "mih_runoff_file = pd.read_csv(dir + 'MiHurRunoff_analysis19502022_prior19001969_1m.csv')\n",
    "mih_precip_file = pd.read_csv(dir + 'MiHurPrecip_analysis19502022_prior19001969_1m.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Year  Month      Median  2.5 Percentile  97.5 Percentile\n",
      "0    1950.0    1.0   67.245050       51.865840        84.204657\n",
      "1    1950.0    2.0   35.728114       20.270061        50.587482\n",
      "2    1950.0    3.0   12.926938       -2.109247        28.563223\n",
      "3    1950.0    4.0   12.655983        3.428071        22.222697\n",
      "4    1950.0    5.0   -3.229512       -9.853121         3.477014\n",
      "..      ...    ...         ...             ...              ...\n",
      "863  2021.0   12.0  112.903571       99.068128       126.926402\n",
      "864  2022.0    1.0  139.083649      125.006839       153.776202\n",
      "865  2022.0    2.0   68.063946       54.649119        81.100302\n",
      "866  2022.0    3.0   39.705374       26.086656        53.065299\n",
      "867  2022.0    4.0   12.252169        3.359856        21.576276\n",
      "\n",
      "[868 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(sup_evap_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_evap = convert_mm_to_cms_l2(sup_evap_file, 'Superior')\n",
    "sup_runoff = convert_mm_to_cms_l2(sup_runoff_file, 'Superior')\n",
    "sup_precip = convert_mm_to_cms_l2(sup_precip_file, 'Superior')\n",
    "\n",
    "eri_evap = convert_mm_to_cms_l2(eri_evap_file, 'Erie')\n",
    "eri_runoff = convert_mm_to_cms_l2(eri_runoff_file, 'Erie')\n",
    "eri_precip = convert_mm_to_cms_l2(eri_precip_file, 'Erie')\n",
    "\n",
    "ont_evap = convert_mm_to_cms_l2(ont_evap_file, 'Ontario')\n",
    "ont_runoff = convert_mm_to_cms_l2(ont_runoff_file, 'Ontario')\n",
    "ont_precip = convert_mm_to_cms_l2(ont_precip_file, 'Ontario')\n",
    "\n",
    "mih_evap = convert_mm_to_cms_l2(mih_evap_file, 'MichHuron')\n",
    "mih_runoff = convert_mm_to_cms_l2(mih_runoff_file, 'MichHuron')\n",
    "mih_precip = convert_mm_to_cms_l2(mih_precip_file, 'MichHuron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Year  Month    Median  2.5 Percentile  97.5 Percentile  seconds  \\\n",
      "0    1950.0    1.0   74.9800         61.8440          87.8480  2678400   \n",
      "1    1950.0    2.0   47.2140         35.0710          58.9410  2419200   \n",
      "2    1950.0    3.0   34.2850         21.9170          46.7320  2678400   \n",
      "3    1950.0    4.0   13.0790          4.9639          21.0750  2592000   \n",
      "4    1950.0    5.0   -1.3051         -7.6169           5.3237  2678400   \n",
      "..      ...    ...       ...             ...              ...      ...   \n",
      "863  2021.0   12.0  101.9500         91.1620         113.0600  2678400   \n",
      "864  2022.0    1.0   97.0030         86.1040         107.4900  2678400   \n",
      "865  2022.0    2.0   50.9510         40.9880          60.8990  2419200   \n",
      "866  2022.0    3.0   28.0770         14.6670          41.8310  2678400   \n",
      "867  2022.0    4.0    5.2800         -2.7979          14.0110  2592000   \n",
      "\n",
      "      Median_cms      2.5_cms     97.5_cms  \n",
      "0    1783.490450  1471.034721  2089.571473  \n",
      "1    1243.368356   923.585623  1552.195837  \n",
      "2     815.510404   521.322488  1111.577430  \n",
      "3     321.469912   122.008142   518.004311  \n",
      "4     -31.043390  -181.177226   126.630676  \n",
      "..           ...          ...          ...  \n",
      "863  2425.004686  2168.398991  2689.269542  \n",
      "864  2307.334277  2048.088312  2556.780320  \n",
      "865  1341.781274  1079.408272  1603.759256  \n",
      "866   667.845577   348.872425   995.001187  \n",
      "867   129.777593   -68.769835   344.377623  \n",
      "\n",
      "[868 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(mih_evap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we prepare the data for training and testing. We set the features 'X' as total over lake\n",
    "precipitation, total over lake evaporation, and the average air temperature over each lake. The\n",
    "targets 'y' are RNBS for each lake simultaeously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              su_evap_y    su_precip    su_runoff    er_evap_y    er_precip  \\\n",
      "1979-01-01  2680.892922  1494.874063   257.166155   312.941786   786.010043   \n",
      "1979-02-01   910.966970  1788.406043   281.665468    93.454255   655.479311   \n",
      "1979-03-01   332.175362  3351.435924   682.915606   128.148602   739.937556   \n",
      "1979-04-01   113.220853  1821.843920  2949.727473     0.291687  1099.047531   \n",
      "1979-05-01   -68.105721  3272.661548  4323.088740    85.882325   825.281810   \n",
      "...                 ...          ...          ...          ...          ...   \n",
      "2010-08-01   685.641445  2311.430246   615.482288  1175.825652   425.954992   \n",
      "2010-09-01  2307.301820  3786.534086  1019.244390  1840.633000   692.348476   \n",
      "2010-10-01  2614.566215  1281.846080   856.096629  1781.961770   795.875877   \n",
      "2010-11-01  3466.873675  2140.159834   862.461925  1370.139640   745.499460   \n",
      "2010-12-01  4341.156823  1239.853513   629.275467   992.495179   446.836078   \n",
      "\n",
      "              er_runoff   on_evap_y   on_precip    on_runoff    mh_evap_y  \\\n",
      "1979-01-01   635.819482  529.773676  886.220815  1220.709379  1649.954635   \n",
      "1979-02-01   580.821904  467.532452  368.440811   831.329448   848.794965   \n",
      "1979-03-01  1729.681862  164.313160  364.154641  2790.598417   128.876095   \n",
      "1979-04-01  1657.182350   61.222621  688.929576  2417.927199   110.065163   \n",
      "1979-05-01   713.979876   -0.970961  521.995202  1058.894415   -37.577463   \n",
      "...                 ...         ...         ...          ...          ...   \n",
      "2010-08-01    66.091510  469.128550  418.376848   440.023148   994.263814   \n",
      "2010-09-01    77.598457  615.181696  575.330266   405.554668  2059.285277   \n",
      "2010-10-01   186.588784  589.978779  542.505959  1269.679697  2254.742954   \n",
      "2010-11-01   364.138677  623.556803  531.401289   943.849653  2694.114001   \n",
      "2010-12-01   522.889206  971.315614  475.508886  1454.915248  3102.911832   \n",
      "\n",
      "              mh_precip    mh_runoff  \n",
      "1979-01-01  1881.727520   794.459603  \n",
      "1979-02-01  1014.677484   761.073950  \n",
      "1979-03-01  2183.336735  3001.820415  \n",
      "1979-04-01  1960.428179  4220.229668  \n",
      "1979-05-01  1528.502218  3061.285954  \n",
      "...                 ...          ...  \n",
      "2010-08-01  1384.119889   720.722334  \n",
      "2010-09-01  2988.817284   951.210764  \n",
      "2010-10-01   977.613463   875.332736  \n",
      "2010-11-01  1228.954475   975.789853  \n",
      "2010-12-01  1043.977005  1136.981108  \n",
      "\n",
      "[384 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Features\n",
    "X = pd.DataFrame({\n",
    "    'su_pcp': data_1['WaterSuperior_cms'],\n",
    "    'er_pcp': data_1['WaterErie_cms'],\n",
    "    'on_pcp': data_1['WaterOntario_cms'],\n",
    "    'mh_pcp': data_1['WaterMichHuron_cms'], #data_1['WaterMichigan']+data_1['WaterHuron'], # add the sums\n",
    "    'su_evap': data_2['WaterSuperior_cms'],\n",
    "    'er_evap': data_2['WaterErie_cms'],\n",
    "    'on_evap': data_2['WaterOntario_cms'],\n",
    "    'mh_evap': data_2['WaterMichHuron_cms'], #data_2['WaterMichigan']+data_2['WaterHuron'], # add the sums\n",
    "    'su_tmp': data_3['WaterSuperior'],\n",
    "    'er_tmp': data_3['WaterErie'],\n",
    "    'on_tmp': data_3['WaterOntario'],\n",
    "    'mh_tmp': (data_3['WaterMichigan']+data_3['WaterHuron'])/2 # take the average temp\n",
    "})\n",
    "\n",
    "# Set the index by date\n",
    "X.set_index(pd.to_datetime(data_1[['year', 'month']].assign(day=1)), inplace=True)\n",
    "\n",
    "# Targets are the components of NBS (P, E, R)\n",
    "targets = pd.DataFrame({\n",
    "    'su_evap_y': sup_evap['Median_cms'],\n",
    "    'su_precip': sup_precip['Median_cms'],\n",
    "    'su_runoff': sup_runoff['Median_cms'],\n",
    "    'er_evap_y': eri_evap['Median_cms'],\n",
    "    'er_precip': eri_precip['Median_cms'],\n",
    "    'er_runoff': eri_runoff['Median_cms'],\n",
    "    'on_evap_y': ont_evap['Median_cms'],\n",
    "    'on_precip': ont_precip['Median_cms'],\n",
    "    'on_runoff': ont_runoff['Median_cms'],\n",
    "    'mh_evap_y': mih_evap['Median_cms'],\n",
    "    'mh_precip': mih_precip['Median_cms'],\n",
    "    'mh_runoff': mih_runoff['Median_cms'],\n",
    "})\n",
    "\n",
    "# Set the index of the targets\n",
    "targets.set_index(pd.to_datetime(eri_evap[['Year', 'Month']].assign(day=1)), inplace=True)\n",
    "\n",
    "# Merge the features and targets to align with the dates\n",
    "# Drops the dates where we don't have CFS data \n",
    "merged_df = pd.merge(X, targets, left_index=True, right_index=True, how='inner')\n",
    "\n",
    "# Pull the target variables back out \n",
    "y = merged_df[['su_evap_y', 'su_precip', 'su_runoff', 'er_evap_y', 'er_precip', 'er_runoff',\n",
    "               'on_evap_y', 'on_precip', 'on_runoff', 'mh_evap_y', 'mh_precip', 'mh_runoff']]\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and testing data sets. We could do it as a random 80/20 split\n",
    "but instead we set split the data set by date ranges. This can easily be adjusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "train_start_date = '1979-01-01'\n",
    "train_end_date = '2004-12-01'\n",
    "# Testing dataset\n",
    "val_start_date = '2005-01-01'\n",
    "val_end_date = '2011-01-01'\n",
    "\n",
    "X_train = X[train_start_date:train_end_date]\n",
    "y_train = y[train_start_date:train_end_date]\n",
    "X_test = X[val_start_date:val_end_date]\n",
    "y_test = y[val_start_date:val_end_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (312, 12)\n",
      "Shape of y_train: (312, 12)\n",
      "Shape of X_test: (72, 12)\n",
      "Shape of y_test: (72, 12)\n"
     ]
    }
   ],
   "source": [
    "# Verify shapes\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is best practice to standardize the data from 0-1 before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(312, 12)\n",
      "(72, 12)\n"
     ]
    }
   ],
   "source": [
    "# Standardize the data\n",
    "x_scaler = StandardScaler()\n",
    "y_scaler = StandardScaler()\n",
    "X_train_scaled = x_scaler.fit_transform(X_train)\n",
    "X_test_scaled = x_scaler.fit_transform(X_test)\n",
    "y_train_scaled = y_scaler.fit_transform(y_train)\n",
    "y_test_scaled = y_scaler.fit_transform(y_test)\n",
    "\n",
    "print(X_train_scaled.shape)\n",
    "print(X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Below we train different models using the same data and calculate the r squared values on the \n",
    "test data to compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r squared value for the model is 0.8280261388798332\n",
      "Mean Squared Error: 0.1719738611201668\n"
     ]
    }
   ],
   "source": [
    "# Testing Different Kernels\n",
    "# Basic kernel using ConstantKernel: r2 = 0.8259\n",
    "#kernel = ConstantKernel(1.0, (1e-3, 1e3)) * RBF(1.0, (1e-2, 1e2))\n",
    "\n",
    "# Matt's optimal kernel: r2 = 0.8321\n",
    "kernel = 1.0 * Matern(nu=1.5) * RationalQuadratic()\n",
    "\n",
    "# Test to add a seasonality component: r2 = 0.8279\n",
    "#period = 3.0  # Period of the season\n",
    "#kernel = ConstantKernel(1.0, (1e-3, 1e3)) * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2)) + ExpSineSquared(length_scale=1.0, periodicity=period, periodicity_bounds=(1e-2, 1e2))\n",
    "\n",
    "# Set up the model\n",
    "gpr = GaussianProcessRegressor(kernel=kernel, alpha=0.1, n_restarts_optimizer=10, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "gpr.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(gpr, 'GP_trained_model.joblib')\n",
    "joblib.dump(x_scaler, 'x_scaler.joblib')\n",
    "joblib.dump(y_scaler, 'y_scaler.joblib')\n",
    "\n",
    "# Predictions\n",
    "y_pred, sigma = gpr.predict(X_test_scaled, return_std=True)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test_scaled, y_pred)\n",
    "r_squared = r2_score(y_test_scaled, y_pred)\n",
    "print(f\"The r squared value for the model is {r_squared}\")\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r squared value for the model is 0.6900094629075637\n",
      "Mean Squared Error: 120295.37954958137\n"
     ]
    }
   ],
   "source": [
    "## Random Forest Regressor Model: r2 = 0.7389\n",
    "\n",
    "# Initialize RandomForestRegressor\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(model, 'RF_trained_model.joblib')\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "print(f\"The r squared value for the model is {r_squared}\")\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 1916398.7500 - val_loss: 1924345.6250\n",
      "Epoch 2/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1904733.6250 - val_loss: 1923514.3750\n",
      "Epoch 3/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1846397.5000 - val_loss: 1922388.6250\n",
      "Epoch 4/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1930362.6250 - val_loss: 1920776.1250\n",
      "Epoch 5/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1859909.2500 - val_loss: 1918465.6250\n",
      "Epoch 6/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1890100.2500 - val_loss: 1915144.3750\n",
      "Epoch 7/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1890050.3750 - val_loss: 1910493.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1917566.3750 - val_loss: 1904111.1250\n",
      "Epoch 9/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1809362.1250 - val_loss: 1895641.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1801235.5000 - val_loss: 1884679.1250\n",
      "Epoch 11/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1871705.0000 - val_loss: 1870463.5000\n",
      "Epoch 12/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1798692.8750 - val_loss: 1852988.2500\n",
      "Epoch 13/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1803447.5000 - val_loss: 1831560.8750\n",
      "Epoch 14/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1834234.0000 - val_loss: 1805883.1250\n",
      "Epoch 15/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1728236.7500 - val_loss: 1775678.5000\n",
      "Epoch 16/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1695648.7500 - val_loss: 1740387.2500\n",
      "Epoch 17/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1650985.5000 - val_loss: 1700036.8750\n",
      "Epoch 18/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1627176.8750 - val_loss: 1654703.5000\n",
      "Epoch 19/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1596988.6250 - val_loss: 1603762.5000\n",
      "Epoch 20/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1548539.8750 - val_loss: 1548592.8750\n",
      "Epoch 21/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1446582.2500 - val_loss: 1489567.5000\n",
      "Epoch 22/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1436639.6250 - val_loss: 1426778.2500\n",
      "Epoch 23/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1411911.3750 - val_loss: 1361010.8750\n",
      "Epoch 24/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1302770.7500 - val_loss: 1294361.2500\n",
      "Epoch 25/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1193839.2500 - val_loss: 1228378.7500\n",
      "Epoch 26/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1187952.3750 - val_loss: 1162024.2500\n",
      "Epoch 27/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1114209.8750 - val_loss: 1098675.5000\n",
      "Epoch 28/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1024090.2500 - val_loss: 1038472.0000\n",
      "Epoch 29/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 994062.8750 - val_loss: 982285.5625\n",
      "Epoch 30/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 943116.8750 - val_loss: 931020.0625\n",
      "Epoch 31/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 905593.4375 - val_loss: 884000.9375\n",
      "Epoch 32/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 818558.0625 - val_loss: 842643.4375\n",
      "Epoch 33/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 812644.0625 - val_loss: 805314.1875\n",
      "Epoch 34/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 747783.0625 - val_loss: 772831.8125\n",
      "Epoch 35/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 721921.0000 - val_loss: 744207.3750\n",
      "Epoch 36/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 697930.6875 - val_loss: 719334.7500\n",
      "Epoch 37/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 657045.8125 - val_loss: 697377.6250\n",
      "Epoch 38/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 642965.8750 - val_loss: 678605.6875\n",
      "Epoch 39/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 621125.6875 - val_loss: 662590.5625\n",
      "Epoch 40/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 640517.6250 - val_loss: 648197.5000\n",
      "Epoch 41/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 616649.8125 - val_loss: 635843.6875\n",
      "Epoch 42/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 574213.6250 - val_loss: 625037.3125\n",
      "Epoch 43/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 552710.6875 - val_loss: 615936.1250\n",
      "Epoch 44/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 577686.8125 - val_loss: 607320.3750\n",
      "Epoch 45/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 545330.1250 - val_loss: 600173.5625\n",
      "Epoch 46/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 575083.7500 - val_loss: 593544.3750\n",
      "Epoch 47/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 561466.2500 - val_loss: 587862.2500\n",
      "Epoch 48/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 540278.2500 - val_loss: 582863.1250\n",
      "Epoch 49/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 561430.1875 - val_loss: 578375.2500\n",
      "Epoch 50/50\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 529259.5625 - val_loss: 574313.7500\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
      "The r squared value for the model is 0.005460813641548157\n",
      "Mean Squared Error: 538670.9622856887\n"
     ]
    }
   ],
   "source": [
    "## Neural Network: r2 = 0.4002\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the neural network architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(12)  # Number of targets\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')  # Using mean squared error (mse) as the loss function\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(model,'NN_trained_model.joblib')\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "print(f\"The r squared value for the model is {r_squared}\")\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
