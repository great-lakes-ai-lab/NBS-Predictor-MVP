{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7je_weK4pWKZ"
      },
      "outputs": [],
      "source": [
        "## This script pulls CFS data from AWS for YESTERDAY (most complete). It uses a subprocess function\n",
        "## to call wgrib2 in order to do the file conversions. This is the easiest way to do this on a\n",
        "## windows machine. It will require wgrib2 to be downloaded on that windows machine and the path will\n",
        "## need to be changed to where the executable lives. On a linux or mac, the cfgrib library can be imported\n",
        "## and used to do the conversion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Vsm-8P5NpWKa"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta\n",
        "import os\n",
        "import xarray as xr\n",
        "from dateutil import relativedelta\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import urllib.request\n",
        "import urllib.error\n",
        "import boto3\n",
        "from botocore import UNSIGNED\n",
        "from botocore.config import Config\n",
        "import netCDF4 as nc\n",
        "from netCDF4 import Dataset\n",
        "import glob\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ewIT_oFpXX3",
        "outputId": "caae33cf-df9c-4da8-a261-b1fff5b06583"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Mount my google drive when working in colab notebooks\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      3\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "# Mount my google drive when working in colab notebooks\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jTkQaLy9QXn"
      },
      "outputs": [],
      "source": [
        "def download_grb2_aws(product, utc, bucket_name, folder_path, download_dir):\n",
        "\n",
        "    num_files_downloaded = 0\n",
        "\n",
        "    # Create a boto3 client for S3\n",
        "    s3_config = Config(signature_version=UNSIGNED)\n",
        "    s3 = boto3.client('s3', config=s3_config)\n",
        "\n",
        "    # List all objects in the specified folder path\n",
        "    continuation_token = None\n",
        "    objects = []\n",
        "\n",
        "    # Use a loop to handle pagination\n",
        "    while True:\n",
        "        list_objects_args = {'Bucket': bucket_name, 'Prefix': folder_path}\n",
        "        if continuation_token:\n",
        "            list_objects_args['ContinuationToken'] = continuation_token\n",
        "\n",
        "        list_objects_response = s3.list_objects_v2(**list_objects_args)\n",
        "\n",
        "        objects.extend(list_objects_response.get('Contents', []))\n",
        "\n",
        "        if not list_objects_response.get('IsTruncated', False):\n",
        "            break\n",
        "\n",
        "        continuation_token = list_objects_response.get('NextContinuationToken')\n",
        "\n",
        "    # Iterate over each object and download if it ends with '.grb2'\n",
        "    for obj in objects:\n",
        "        key = obj['Key']\n",
        "        if product in key and key.endswith('grib.grb2'): #if key.endswith('.grb2'):\n",
        "            local_file_path = os.path.join(download_dir, os.path.relpath(key, folder_path))\n",
        "\n",
        "            # Ensure the directory structure exists\n",
        "            os.makedirs(os.path.dirname(local_file_path), exist_ok=True)\n",
        "\n",
        "            # Download the file\n",
        "            s3.download_file(bucket_name, key, local_file_path)\n",
        "            num_files_downloaded += 1\n",
        "\n",
        "            print(f\"Downloaded: {key}\")\n",
        "\n",
        "    print(f'Total number of CFS files downloaded from AWS: {num_files_downloaded}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHrZ4f7-pWKc"
      },
      "outputs": [],
      "source": [
        "def get_files(directory, where, format):\n",
        "    \"\"\"\n",
        "    Get a list of all GRIB2 files in the specified directory.\n",
        "\n",
        "    Parameters:\n",
        "    - directory: Path to the directory containing the GRIB2 files.\n",
        "    - where: 'starts' or 'ends'\n",
        "    - format: either '.grb2' or '.nc'\n",
        "    Returns:\n",
        "    - List of file paths to the GRIB2 files.\n",
        "    \"\"\"\n",
        "    files = []\n",
        "    for file_name in os.listdir(directory):\n",
        "        if where == 'ends':\n",
        "            if file_name.endswith(format):\n",
        "                file_path = os.path.join(directory, file_name)\n",
        "                files.append(file_path)\n",
        "        elif where == 'starts':\n",
        "            if file_name.startswith(format):\n",
        "                file_path = os.path.join(directory, file_name)\n",
        "                files.append(file_path)\n",
        "    return files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4Q2En12pWKc"
      },
      "outputs": [],
      "source": [
        "## In order to convert grb2 files to netcdf on a windows machine, you need to download wgrib2.exe\n",
        "## https://www.ftp.cpc.ncep.noaa.gov/wd51we/wgrib2/Windows10/v3.1.3/wgrib2.exe\n",
        "\n",
        "import subprocess\n",
        "\n",
        "def grb2_to_netcdf(input_file, output_file):\n",
        "    # Define the command to convert GRIB2 to NetCDF using wgrib2\n",
        "    # Need to download wgrib2 and write the full path unless it is set to your PATH\n",
        "    command = [\"C:/Users/fitzpatrick/Downloads/wgrib2\", input_file, \"-netcdf\", output_file]\n",
        "\n",
        "    # Execute the command\n",
        "    try:\n",
        "        subprocess.run(command, check=True)\n",
        "        # Remove the grb2 file\n",
        "        os.remove(input_file)\n",
        "        print(f\"Conversion successful. NetCDF file saved as {output_file}\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Conversion failed with error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def merge_netcdf_files(input_files):\n",
        "    # Group input files by common prefix\n",
        "    file_groups = defaultdict(list)\n",
        "    for file in input_files:\n",
        "        prefix = file.split('.')[0] + '.' + file.split('.')[1] + '.' + file.split('.')[2]  # Extracting prefix\n",
        "        file_groups[prefix].append(file)\n",
        "\n",
        "    # Iterate over each group of files and merge them\n",
        "    for prefix, files in file_groups.items():\n",
        "        # List to store all datasets\n",
        "        datasets = []\n",
        "\n",
        "        # Loop through each input file\n",
        "        for file in files:\n",
        "            # Open the NetCDF file using xarray\n",
        "            ds = xr.open_dataset(file)\n",
        "\n",
        "            # Is this a pgb or flx file?\n",
        "            file_prefix = os.path.basename(file).split('.')[0]\n",
        "\n",
        "            if file_prefix == 'pgbf':\n",
        "                ds = ds[['APCP_surface']]  # Keep only APCP_surface variable\n",
        "                # Add dataset to the list\n",
        "                datasets.append(ds)\n",
        "\n",
        "            elif file_prefix == 'flxf':\n",
        "                ds = ds[['LHTFL_surface', 'TMP_2maboveground']] # Keep only LHTFL and TMP\n",
        "                # Add dataset to the list\n",
        "                datasets.append(ds)\n",
        "\n",
        "            else:\n",
        "                print('File not compatible')\n",
        "            # Close the dataset\n",
        "            ds.close()        \n",
        "        \n",
        "        # Merge all datasets along time dimension\n",
        "        combined = xr.concat(datasets, dim='time')\n",
        "\n",
        "        # Save to a new NetCDF file\n",
        "        output_filename = f\"{prefix}.allmonths.nc\"\n",
        "        combined.to_netcdf(output_filename)\n",
        "        print(f'Complete: {output_filename}')\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cut_remap_netcdf(input_file, reference_file, output_file, lonlatbox):\n",
        "    \"\"\"\n",
        "    Cut a NetCDF file to a specified lon-lat bounding box and save it as a new file.\n",
        "\n",
        "    Parameters:\n",
        "        input_file (str): Path to the input NetCDF file.\n",
        "        lonlatbox (list): Bounding box in the format [lon_min, lon_max, lat_min, lat_max].\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Unpack the lon-lat bounding box\n",
        "    lon_min, lon_max, lat_min, lat_max = lonlatbox\n",
        "\n",
        "    # Open the input NetCDF file\n",
        "    ds = xr.open_dataset(input_file)\n",
        "    ds_mask = xr.open_dataset(reference_file)\n",
        "\n",
        "    # Extract lonlatbox values\n",
        "    lon_min, lon_max, lat_min, lat_max = lonlatbox\n",
        "\n",
        "    # Select lat/lon range\n",
        "    ds_cut = ds.sel(longitude=slice(lon_min, lon_max), latitude=slice(lat_min, lat_max))\n",
        "\n",
        "    # Interpolate the input data onto the grid of the reference data\n",
        "    ds_remapped = ds_cut.interp_like(ds_mask)\n",
        "\n",
        "    # Save the remapped data to a new NetCDF file\n",
        "    ds_remapped.to_netcdf(output_file)\n",
        "    print('Processing complete: ',output_file)\n",
        "    \n",
        "    return ds_remapped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_variables(filename):\n",
        "    try:\n",
        "        # Open the NetCDF file\n",
        "        with nc.Dataset(filename, 'r') as rootgrp:\n",
        "            print(f\"Variables in {filename}:\")\n",
        "            # Iterate over each variable in the NetCDF file\n",
        "            for varname, var in rootgrp.variables.items():\n",
        "                # Print variable name\n",
        "                print(f\"\\nVariable: {varname}\")\n",
        "                \n",
        "                # Print variable dimensions\n",
        "                print(f\"Dimensions: {var.dimensions}\")\n",
        "                \n",
        "                # Print variable attributes\n",
        "                print(\"Attributes:\")\n",
        "                for attrname in var.ncattrs():\n",
        "                    print(f\"  {attrname}: {getattr(var, attrname)}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7ci2KgQpWKd",
        "outputId": "1bdd707a-e5e9-42cb-e85b-74f8911a98cf"
      },
      "outputs": [],
      "source": [
        "## User Inputs ##\n",
        "\n",
        "#Local path\n",
        "dir = 'C:/Users/fitzpatrick/Desktop/Data/'\n",
        "mask = 'C:/Users/fitzpatrick/Desktop/Data/Input/GL_mask.nc'\n",
        "\n",
        "#Google drive path if using Google Colab notebooks\n",
        "#download_dir = '/content/drive/MyDrive/BIL SA Project/Modeling/Data-driven Modeling/Input datasets/Downloaded Data/'\n",
        "\n",
        "## Presets ##\n",
        "products = ['pgb','flx']\n",
        "utc = ['00','06','12','18']\n",
        "lonlatbox = [250,295,30,70]\n",
        "\n",
        "today = datetime.today().strftime('%Y%m%d')\n",
        "yesterday = (datetime.today() - timedelta(days=2)).strftime('%Y%m%d') #currently 2 days prior"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Directory already exists.\n"
          ]
        }
      ],
      "source": [
        "#download_dir = f'{dir}{yesterday}/downloaded/'\n",
        "download_dir = f'{dir}20240625/downloaded/'\n",
        "if not os.path.exists(download_dir):\n",
        "    os.makedirs(download_dir)\n",
        "else:\n",
        "    print(f\"Directory already exists.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uses the AWS to download the grib2 files\n",
        "bucket_name = 'noaa-cfs-pds'\n",
        "\n",
        "for utc in utc:\n",
        "    for product in products:\n",
        "        folder_path = f'cfs.{yesterday}/{utc}/monthly_grib_01/'\n",
        "        download_grb2_aws(product, utc, bucket_name, folder_path, download_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "43VRNJNFpWKe",
        "outputId": "ce63950c-5857-4b11-d72c-4aaddb0e1313"
      },
      "outputs": [],
      "source": [
        "# set up a loop to convert all the grib2 files to netcdf in a given directory\n",
        "grb2_files = get_files(download_dir, 'ends', '.grb2')\n",
        "print(download_dir)\n",
        "print(grb2_files)\n",
        "for grib2_file in grb2_files:\n",
        "    output_netcdf_file = grib2_file[:-5] + '.nc'  # Replace .grb2 with .nc in file name\n",
        "    grb2_to_netcdf(grib2_file, output_netcdf_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "flxf\n",
            "flxf\n",
            "flxf\n",
            "flxf\n",
            "flxf\n",
            "flxf\n",
            "flxf\n",
            "flxf\n",
            "flxf\n",
            "flxf\n",
            "flxf\n"
          ]
        },
        {
          "ename": "PermissionError",
          "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\fitzpatrick\\\\Desktop\\\\Data\\\\20240625\\\\downloaded\\\\test\\\\flxf.01.2024062500.allmonths.nc'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\fitzpatrick\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xarray\\backends\\file_manager.py:211\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[1;34m(self, needs_lock)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 211\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\fitzpatrick\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xarray\\backends\\lru_cache.py:56\u001b[0m, in \u001b[0;36mLRUCache.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m---> 56\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mmove_to_end(key)\n",
            "\u001b[1;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('C:\\\\Users\\\\fitzpatrick\\\\Desktop\\\\Data\\\\20240625\\\\downloaded\\\\test\\\\flxf.01.2024062500.allmonths.nc',), 'a', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False)), 'bc84fe84-4c73-44b8-8cdf-12afe2e0c4a0']",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# This step drops unused variables and merges the months together into a 1 netcdf file\u001b[39;00m\n\u001b[0;32m      2\u001b[0m nc_files \u001b[38;5;241m=\u001b[39m get_files(download_dir\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mends\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.nc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmerge_netcdf_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnc_files\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[22], line 41\u001b[0m, in \u001b[0;36mmerge_netcdf_files\u001b[1;34m(input_files)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Save to a new NetCDF file\u001b[39;00m\n\u001b[0;32m     40\u001b[0m output_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.allmonths.nc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 41\u001b[0m \u001b[43mcombined\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_netcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_filename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComplete: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\fitzpatrick\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xarray\\core\\dataset.py:2327\u001b[0m, in \u001b[0;36mDataset.to_netcdf\u001b[1;34m(self, path, mode, format, group, engine, encoding, unlimited_dims, compute, invalid_netcdf)\u001b[0m\n\u001b[0;32m   2324\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   2325\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_netcdf\n\u001b[1;32m-> 2327\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_netcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore  # mypy cannot resolve the overloads:(\u001b[39;49;00m\n\u001b[0;32m   2328\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2331\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2335\u001b[0m \u001b[43m    \u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munlimited_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmultifile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2338\u001b[0m \u001b[43m    \u001b[49m\u001b[43minvalid_netcdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minvalid_netcdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2339\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\fitzpatrick\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xarray\\backends\\api.py:1320\u001b[0m, in \u001b[0;36mto_netcdf\u001b[1;34m(dataset, path_or_file, mode, format, group, engine, encoding, unlimited_dims, compute, multifile, invalid_netcdf)\u001b[0m\n\u001b[0;32m   1316\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1317\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1318\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munrecognized option \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvalid_netcdf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for engine \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1319\u001b[0m         )\n\u001b[1;32m-> 1320\u001b[0m store \u001b[38;5;241m=\u001b[39m \u001b[43mstore_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unlimited_dims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1323\u001b[0m     unlimited_dims \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mencoding\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munlimited_dims\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
            "File \u001b[1;32mc:\\Users\\fitzpatrick\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xarray\\backends\\netCDF4_.py:408\u001b[0m, in \u001b[0;36mNetCDF4DataStore.open\u001b[1;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[0;32m    402\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m    403\u001b[0m     clobber\u001b[38;5;241m=\u001b[39mclobber, diskless\u001b[38;5;241m=\u001b[39mdiskless, persist\u001b[38;5;241m=\u001b[39mpersist, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m\n\u001b[0;32m    404\u001b[0m )\n\u001b[0;32m    405\u001b[0m manager \u001b[38;5;241m=\u001b[39m CachingFileManager(\n\u001b[0;32m    406\u001b[0m     netCDF4\u001b[38;5;241m.\u001b[39mDataset, filename, mode\u001b[38;5;241m=\u001b[39mmode, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[0;32m    407\u001b[0m )\n\u001b[1;32m--> 408\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoclose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautoclose\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\fitzpatrick\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xarray\\backends\\netCDF4_.py:355\u001b[0m, in \u001b[0;36mNetCDF4DataStore.__init__\u001b[1;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group \u001b[38;5;241m=\u001b[39m group\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[1;32m--> 355\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mds\u001b[49m\u001b[38;5;241m.\u001b[39mdata_model\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39mfilepath()\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_remote \u001b[38;5;241m=\u001b[39m is_remote_uri(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename)\n",
            "File \u001b[1;32mc:\\Users\\fitzpatrick\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xarray\\backends\\netCDF4_.py:417\u001b[0m, in \u001b[0;36mNetCDF4DataStore.ds\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mds\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\fitzpatrick\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xarray\\backends\\netCDF4_.py:411\u001b[0m, in \u001b[0;36mNetCDF4DataStore._acquire\u001b[1;34m(self, needs_lock)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 411\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_nc4_require_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
            "File \u001b[1;32mc:\\Users\\fitzpatrick\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\fitzpatrick\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xarray\\backends\\file_manager.py:199\u001b[0m, in \u001b[0;36mCachingFileManager.acquire_context\u001b[1;34m(self, needs_lock)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21macquire_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    198\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m     file, cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_acquire_with_cache_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mneeds_lock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m file\n",
            "File \u001b[1;32mc:\\Users\\fitzpatrick\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xarray\\backends\\file_manager.py:217\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[1;34m(self, needs_lock)\u001b[0m\n\u001b[0;32m    215\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    216\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode\n\u001b[1;32m--> 217\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opener\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "File \u001b[1;32msrc\\\\netCDF4\\\\_netCDF4.pyx:2470\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32msrc\\\\netCDF4\\\\_netCDF4.pyx:2107\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\fitzpatrick\\\\Desktop\\\\Data\\\\20240625\\\\downloaded\\\\test\\\\flxf.01.2024062500.allmonths.nc'"
          ]
        }
      ],
      "source": [
        "# This step drops unused variables and merges the months together into a 1 netcdf file\n",
        "nc_files = get_files(download_dir+'test/', 'ends', '.nc')\n",
        "merge_netcdf_files(nc_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing complete:  C:/Users/fitzpatrick/Desktop/Data/20240625/downloaded/flxf.01.2024062500.allmonths.GL025.nc\n",
            "Processing complete:  C:/Users/fitzpatrick/Desktop/Data/20240625/downloaded/flxf.01.2024062506.allmonths.GL025.nc\n",
            "Processing complete:  C:/Users/fitzpatrick/Desktop/Data/20240625/downloaded/flxf.01.2024062512.allmonths.GL025.nc\n",
            "Processing complete:  C:/Users/fitzpatrick/Desktop/Data/20240625/downloaded/flxf.01.2024062518.allmonths.GL025.nc\n",
            "Processing complete:  C:/Users/fitzpatrick/Desktop/Data/20240625/downloaded/pgbf.01.2024062500.allmonths.GL025.nc\n",
            "Processing complete:  C:/Users/fitzpatrick/Desktop/Data/20240625/downloaded/pgbf.01.2024062506.allmonths.GL025.nc\n",
            "Processing complete:  C:/Users/fitzpatrick/Desktop/Data/20240625/downloaded/pgbf.01.2024062512.allmonths.GL025.nc\n",
            "Processing complete:  C:/Users/fitzpatrick/Desktop/Data/20240625/downloaded/pgbf.01.2024062518.allmonths.GL025.nc\n"
          ]
        }
      ],
      "source": [
        "file_list = get_files(download_dir, 'ends', '.nc')\n",
        "\n",
        "# Use the function defined above to cut the netcdf files to the GL domain and upscale to 0.25 degrees\n",
        "for file in file_list:\n",
        "    # Split the filename\n",
        "    filename = os.path.basename(file) #pulls the filename from the entire path\n",
        "    name, ext = os.path.splitext(filename) #splits the filename at the '.nc' so we can change the filename\n",
        "    # Create new file names for the new files\n",
        "    new_filename = name + '.GL025' + ext\n",
        "    new_netcdf = cut_remap_netcdf(file, mask, download_dir+new_filename, lonlatbox)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
